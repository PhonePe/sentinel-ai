{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"index.html","title":"Introduction","text":""},{"location":"index.html#introduction","title":"Introduction","text":"<p>Sentinel AI is a high level Java framework that allows you to build and deploy AI agents using a variety of LLMs and tools. It is designed to be easy to use and flexible, allowing you to create agents that can perform a wide range of tasks.</p>"},{"location":"index.html#features","title":"Features","text":"<ul> <li>High level API: Sentinel AI provides a high level API that makes it easy to create and deploy agents.</li> <li>Flexible: Sentinel AI is designed to be flexible, allowing you to create agents that can perform a wide range of   tasks.</li> <li>Easy to use: Sentinel AI is easy to use, with a simple and intuitive API that makes it easy to get started.</li> <li>Structured to the core: Sentinel AI uses both structured prompts and output generation to allow for predictable   behaviour from your AI agents.</li> <li>Extensible: Sentinel AI is designed to be extensible, allowing you to add your own custom tools and LLMs.</li> <li>Modular: The framework provides a variety of modules with extensions and tools that you can use to build your   agents.</li> </ul>"},{"location":"index.html#available-modules","title":"Available Modules","text":"<p>Sentinel AI libraries are published on maven central. Sentinel-ai is arranged as modules:</p> <ul> <li><code>sentinel-ai-core</code>: The core library that contains the main classes and interfaces for building agents.</li> <li><code>sentinel-ai-models-simple-openai</code>: Using OpenAI api compliant models for agents.</li> <li><code>sentinel-ai-embedding</code>: Provides embedding models to be used for indexing information in vector databases.</li> <li><code>sentinel-ai-agent-memory</code>: Extension that implements memory extraction and storage from conversations. See Agent Memory.</li> <li><code>sentinel-ai-session</code>: Extension that can be used to store and update information about a conversation session. See Messages and Sessions.</li> <li><code>sentinel-ai-storage-es</code>: Elasticsearch based implementation for storage abstractions for agent memory, sessions etc.</li> <li><code>sentinel-ai-configured-agents</code>: Implementation for Agent Registry and Planner-Worker orchestration. See Agent Registry.</li> <li><code>sentinel-ai-toolbox-remote-http</code>: Flexible toolbox for making declarative HTTP calls to remote services. See Calling Remote Services.</li> <li><code>sentinel-ai-toolbox-mcp</code>: Support for Model Context Protocol (MCP) servers. See Using MCP Servers.</li> <li><code>sentinel-ai-filesystem</code>: Local file system based storage for memories and sessions.</li> </ul>"},{"location":"index.html#additional-features","title":"Additional Features","text":"<ul> <li>Observability: Monitor your agent with the built-in event bus.</li> <li>Agent Registry: Manage and discover agents dynamically.</li> </ul>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<p>Building an agent with Sentinel involves broadly the following steps:</p> <ul> <li>Create agent class.</li> <li>Implement tools, toolboxes or add extensions<ul> <li>Implement agent memory to avoid sending all messages for context or be intelligent across sessions</li> <li>Keep updating session with information to provide some context and a richer visual experience to the user</li> </ul> </li> <li>Instantiate a model and configure it</li> <li>Instantiate an agent and run it</li> </ul>"},{"location":"index.html#add-the-required-dependencies","title":"Add the required dependencies","text":"<p>Latest Version</p> <p>The latest version of the library can be found here.</p> <p>Sentinel AI should be included at the top level using the bom. To use the BOM, add the following to the <code>dependencyManagement</code> section of your project.</p> <pre><code>&lt;dependencyManagement&gt;\n    &lt;dependencies&gt;\n        &lt;!-- other stuff --&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n            &lt;artifactId&gt;sentinel-ai-bom&lt;/artifactId&gt;\n            &lt;version&gt;${sentinel-ai.version}&lt;/version&gt;\n            &lt;scope&gt;import&lt;/scope&gt;\n            &lt;type&gt;pom&lt;/type&gt;\n        &lt;/dependency&gt;\n    &lt;/dependencies&gt;\n&lt;/dependencyManagement&gt;\n</code></pre> <p>The core abstractions for Sentinel AI are in the <code>sentinel-ai-core</code> module. To add it to your project add the following dependencies:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n    &lt;artifactId&gt;sentinel-ai-core&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>In order for the agent to work, it needs to use a model. Currently, Sentinel AI supports only OpenAI compliant models. Use the following dependency to add the OpenAI model implementation to your project:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n    &lt;artifactId&gt;sentinel-ai-models-simple-openai&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>OpenAI Client Library</p> <p>We use the Simple OpenAI Client instead of the official OpenAI client as this library provides much more flexibility to configure options on the HTTP client, something, typically needed in production environments to allow for tightened security and performance.</p>"},{"location":"index.html#create-your-agent","title":"Create Your Agent","text":"<p>The core AI agent abstraction in Sentinel AI is the generic <code>Agent</code> abstract class. The complexity of model interaction is completely abstracted out from users. The <code>Agent</code> class requires the following type paramters:</p> <ul> <li><code>R</code> - The type of the request object that the agent receives. Can be string or any other complex java types.</li> <li><code>T</code> - The type of the response object that the agent returns. Can be string or any other complex java types.</li> <li><code>A</code> - The agent subtype. This is the class you are currently implementing.</li> </ul> <p>Basic things you'll need to supply to the agent to make it work are:</p> <ul> <li>The class type of the response type (This is a bit redundant but is needed for the serialization/deserialization   framework inside the agent to work)</li> <li>The system prompt for the agent. This is the prompt that will be used to initialize the agent and provide context for   the conversation.</li> <li>The agent setup. This is the configuration object that will be used to configure the agent. Models and other settings   can be put here.</li> <li>Other optional parameters like tools, toolboxes, extensions etc.</li> </ul> <p>Here is the implementation for a very simple text based agent:</p> <pre><code>public class TestAgent extends Agent&lt;String, String, TestAgent&gt; {\n\n    public TestAgent(@NonNull AgentSetup setup) {\n        super(String.class, //(1)!\n              \"Greet the user\", //(2)!\n              setup, //(3)!\n              List.of(),\n              Map.of());\n    }\n\n    @Override\n    public String name() { //(4)!\n        return \"test-agent\";\n    }\n}\n</code></pre> <ol> <li>Return type of the agent</li> <li>System prompt</li> <li>Agent setup</li> <li>A human-readable name for the agent. This is used for logging and debugging purposes.</li> </ol>"},{"location":"index.html#create-your-agent-setup","title":"Create Your Agent Setup","text":"<p>This will broadly consist of the following steps:</p> <ul> <li>Create Jackson ObjectMapper for serialization/deserialization</li> <li>Create model object and configure it</li> <li>Create/configure relevant http client</li> <li>User agent setup to configure:<ul> <li>Model</li> <li>ObjectMapper</li> <li>Model Settings (like temperature, max tokens etc.)</li> </ul> </li> <li>Pass the agent setup to the agent</li> </ul> <p>Sample code for creating the agent setup:</p> <pre><code>final var objectMapper = JsonUtils.createMapper(); //(1)!\n\nfinal var httpClient = new OkHttpClient.Builder().build(); //(2)!\n\nfinal var model = new SimpleOpenAIModel&lt;&gt;(\n        \"gpt-4o\", //(3)!\n        SimpleOpenAI.builder() //(4)!\n                .baseUrl(EnvLoader.readEnv(\"OPENAI_ENDPOINT\"))\n                .apiKey(EnvLoader.readEnv(\"OPENAI_API_KEY\"))\n                .objectMapper(objectMapper)\n                .clientAdapter(new OkHttpClientAdapter(httpClient))\n                .build(),\n        objectMapper //(5)!\n);\n\nfinal var agentSetup = AgentSetup.builder()\n        .model(model) //(6)!\n        .mapper(objectMapper) //(7)!\n        .modelSettings(ModelSettings.builder() //(8)!\n                               .temperature(0.1f)\n                               .seed(1)\n                               .build())\n        .build();\n</code></pre> <ol> <li>Creates a preconfigured Object mapper with all the required modules and settings.</li> <li>Creates a OkHttp based HTTP client with default settings.</li> <li>The model name to use.</li> <li>Simple-OpenAI client builder.</li> <li>ObjectMapper to be used by the model.</li> <li>The configured model.</li> <li>The mapper used internally by the agent for setup.</li> <li>Settings for the model. This will depend on the model.</li> </ol>"},{"location":"index.html#bringing-it-all-together","title":"Bringing it all together","text":"<p>We create a small app that does interactive chat.</p> SimpleTextAgentExample.java<pre><code>public class SimpleTextAgentExample {\n\n    public static class TestAgent extends Agent&lt;String, String, TestAgent&gt; {\n\n        public TestAgent(AgentSetup setup) {\n            super(String.class,\n                  \"Converse with the user on any topic\",\n                  setup,\n                  List.of(),\n                  Map.of());\n        }\n\n        @Override\n        public String name() {\n            return \"test-agent\";\n        }\n    }\n\n    public static void main(String[] args) throws Exception {\n        final var objectMapper = JsonUtils.createMapper();\n\n        final var httpClient = new OkHttpClient.Builder().build();\n\n        final var model = new SimpleOpenAIModel&lt;&gt;(\n                \"gpt-4o\",\n                SimpleOpenAI.builder()\n                        .baseUrl(EnvLoader.readEnv(\"OPENAI_ENDPOINT\"))\n                        .apiKey(EnvLoader.readEnv(\"OPENAI_API_KEY\"))\n                        .objectMapper(objectMapper)\n                        .clientAdapter(new OkHttpClientAdapter(httpClient))\n                        .build(),\n                objectMapper\n        );\n\n        final var agentSetup = AgentSetup.builder()\n                .model(model)\n                .mapper(objectMapper)\n                .modelSettings(ModelSettings.builder()\n                                       .temperature(0.1f)\n                                       .seed(1)\n                                       .build())\n                .build();\n\n        final var agent = new TestAgent(agentSetup);\n        final var requestMeta = AgentRequestMetadata.builder()\n                .sessionId(UUID.randomUUID().toString())\n                .build();\n        var response = (AgentOutput&lt;String&gt;) null;\n        Terminal terminal = TerminalBuilder.builder().system(true).build();\n        LineReader lineReader = LineReaderBuilder.builder().terminal(terminal).build();\n\n        String prompt = \"&gt; \";\n        String userInput;\n        while ((userInput = lineReader.readLine(prompt)) != null) {\n            if (userInput.equalsIgnoreCase(\"exit\")) {\n                break;\n            }\n            response = agent.execute(AgentInput.&lt;String&gt;builder()\n                                             .request(userInput)\n                                             .requestMetadata(requestMeta)\n                                             .oldMessages(null != response ? response.getAllMessages() : null)\n                                             .build());\n            System.out.println(response.getData());\n        }\n    }\n}\n</code></pre> <p>You can now run the agent to converse with it. The agent will keep the context of the conversation and will be able to respond to your queries.</p>"},{"location":"agent-memory.html","title":"Agent Memory","text":""},{"location":"agent-memory.html#agent-memory","title":"Agent Memory","text":"<p>Agent Memory is a powerful feature that allows agents to remember information across different sessions and users. Unlike conversation history (which is session-specific and typically ephemeral), Agent Memory extracts semantic, episodic, or procedural information and stores it in a persistent store for long-term retrieval.</p>"},{"location":"agent-memory.html#agent-memory-vs-conversation-history","title":"Agent Memory vs. Conversation History","text":"<p>It is important to distinguish between these two:</p> Feature Conversation History Agent Memory Scope Current Session Cross-session / Cross-user Storage Typically RAM or Session Store Vector Database or File System Retrieval All messages sent to LLM Semantic search based on relevance Content Raw messages Extracted facts, procedures, and events"},{"location":"agent-memory.html#agent-memory-extension","title":"Agent Memory Extension","text":"<p>The <code>AgentMemoryExtension</code> enables memory capabilities. It handles memory retrieval (injecting relevant facts into the prompt) and memory extraction (learning from the current conversation).</p>"},{"location":"agent-memory.html#configuration-options","title":"Configuration Options","text":"<p>The <code>AgentMemoryExtension</code> can be configured using its builder:</p> Option Type Default Description <code>memoryStore</code> <code>AgentMemoryStore</code> Required The storage implementation for memories. <code>memoryExtractionMode</code> <code>MemoryExtractionMode</code> <code>INLINE</code> How memories are extracted. See Extraction Modes. <code>minRelevantReusabilityScore</code> <code>int</code> <code>0</code> Minimum score (0-10) for a memory to be saved or retrieved. Helps filter \"noise\". <code>objectMapper</code> <code>ObjectMapper</code> Default Mapper Used for serializing memory units."},{"location":"agent-memory.html#example-setup","title":"Example Setup","text":"<pre><code>final var memoryExtension = AgentMemoryExtension.builder()\n        .memoryStore(memoryStore)\n        .memoryExtractionMode(MemoryExtractionMode.INLINE)\n        .minRelevantReusabilityScore(7) // Only \"highly reusable\" memories\n        .build();\n\nfinal var agent = new MyAgent(AgentSetup.builder()\n        .model(model)\n        .extension(memoryExtension)\n        .build());\n</code></pre>"},{"location":"agent-memory.html#memory-tools","title":"Memory Tools","text":"<p>The <code>AgentMemoryExtension</code> provides a specialized tool for semantic memory retrieval.</p> Tool Name Description Parameters <code>agent_memory_extension_find_memories</code> Retrieves relevant memories from the persistent store based on a natural language query. <code>query</code> (String) <p>When this extension is registered, the agent is instructed to use this tool to check for relevant background information before proceeding with complex tasks.</p>"},{"location":"agent-memory.html#memory-extraction-modes","title":"Memory Extraction Modes","text":"<p>The <code>MemoryExtractionMode</code> determines the lifecycle of memory creation:</p> Mode Description <code>INLINE</code> Extraction happens during the primary model call using structured output. Nuance: This is the most efficient mode but is not supported in streaming mode. Sentinel AI will automatically force an out-of-band extraction if the agent is run in streaming mode. <code>OUT_OF_BAND</code> Extraction happens as a separate, asynchronous model call after the primary response is generated. This ensures extraction works even with streaming. <code>DISABLED</code> No new memories are extracted. Useful for read-only memory agents."},{"location":"agent-memory.html#storage-implementations","title":"Storage Implementations","text":"<p>Sentinel AI requires an <code>EmbeddingModel</code> to generate vector representations of memories for semantic search.</p>"},{"location":"agent-memory.html#file-system-storage-sentinel-ai-filesystem","title":"File System Storage (<code>sentinel-ai-filesystem</code>)","text":"<p>Ideal for local development or small-scale applications. It stores memories as JSON files and vectors in a local directory.</p> <pre><code>final var storage = FileSystemAgentMemoryStorage.builder()\n        .baseDir(\"./data/memory\")\n        .mapper(objectMapper)\n        .embeddingModel(embeddingModel) // e.g., LocalEmbeddingModel or OpenAIEmbeddingModel\n        .build();\n</code></pre> <p>Performance</p> <p><code>FileSystemAgentMemoryStorage</code> performs a linear scan and manual cosine similarity calculation for search. It is not intended for production use with thousands of memories.</p>"},{"location":"agent-memory.html#elasticsearch-storage-sentinel-ai-storage-es","title":"Elasticsearch Storage (<code>sentinel-ai-storage-es</code>)","text":"<p>Recommended for production. Uses Elasticsearch's native KNN (k-nearest neighbors) search for efficient retrieval.</p> <pre><code>final var storage = ESAgentMemoryStorage.builder()\n        .client(esClient)\n        .embeddingModel(embeddingModel)\n        .indexPrefix(\"prod\") // Optional: prefixes the 'agent-memories' index\n        .build();\n</code></pre> <p>Vector Dimensions</p> <p>The Elasticsearch implementation automatically determines vector dimensions based on the provided <code>EmbeddingModel</code> during initial index creation. If you change your embedding model later, you may need to recreate the index to match the new dimension count.</p>"},{"location":"agent-memory.html#tips-and-nuances","title":"Tips and Nuances","text":"<ul> <li>Reusability Scores: The LLM assigns a reusability score to each extracted memory. Use <code>minRelevantReusabilityScore</code> (e.g., <code>7</code>) to prevent your store from being cluttered with session-specific trivia.</li> <li>Memory Scopes: <ul> <li><code>AGENT</code>: Shared knowledge (e.g., \"Field 'X' in the database refers to User Salary\").</li> <li><code>ENTITY</code>: User-specific (e.g., \"User prefers dark mode\").</li> </ul> </li> <li>Facts Injection: Memories are injected as <code>Facts</code> into the system prompt. This happens automatically based on the <code>userId</code> provided in <code>AgentRequestMetadata</code>.</li> </ul>"},{"location":"agent-memory.html#dangers-and-risks","title":"Dangers and Risks","text":"<ul> <li>PII &amp; Privacy: Since memories are stored persistently across sessions, be extremely careful about extracting Personal Identifiable Information (PII). You can use a <code>AgentMessagesPreProcessor</code> to mask data before it reaches the extraction task.</li> <li>Hallucinations: The LLM might \"remember\" things that weren't explicitly stated or were misunderstood. Periodic auditing of the memory store is recommended.</li> <li>Token Overhead: Retrieving too many memories (high <code>count</code>) can bloat your system prompt and increase costs/latency.</li> <li>Embedding Costs: Every save and every search requires an embedding model call. If using remote models (like OpenAI), this adds to your per-request cost.</li> </ul>"},{"location":"agent-registry.html","title":"Configured Agents and Registry","text":""},{"location":"agent-registry.html#configured-agents-and-registry","title":"Configured Agents and Registry","text":"<p>As powerful as single agents can be,  due to a variety of limitations like context window length, chances of hallucination when large number of tools are exposed to the model etc., it is better to have agents that specialize in doing specific tasks. A common pattern that works out well in a variety of scenarios is to have a high level agent that does the planning and/or orchestration and delegates specific tasks to specialized agents.</p> <p>To allow developers to implement this pattern easily, Sentinel AI provides a way to configure and manage multiple agents through a centralized registry. This allows for easy access and management of different agents that can perform various  tasks. The registry is implemented as an <code>AgentExtension</code> and can be added to any top-level agent implementation.</p>"},{"location":"agent-registry.html#nomenclature","title":"Nomenclature","text":"<p>Let us understand a few fundamental constructs before we dive into the implementation details.</p> <ul> <li><code>ConfiguredAgent</code>: This is an abstraction that represents an agent with a specific configuration.</li> <li><code>AgentCapability</code>: Capabilities define what an agent gets access to. For example, HTTP tools, MCP tools,   local/custom tools etc.</li> <li><code>AgentConfiguration</code>: This represents the configuration details of an agent, including its name, description, input,   output spec, capabilities and other settings.</li> <li><code>AgentConfigurationSource</code>: The agent configuration source is responsible for providing the configuration details   for an agent during the build process. A default in-memory source is provided, but you can implement your own source   based off more permanent storage.</li> <li><code>ConfiguredAgentFactory</code>: This factory is responsible for creating instances of configured agents based on the   provided configuration.</li> <li><code>AgentRegistry</code>: The agent registry is a centralized repository that holds all the configured agents. It allows for   easy retrieval and management of agents and exposes required tools to a Sentinel AI agent to get details about agents   and to invoke them to get work done.</li> </ul> <p>All tools from different sources are registered globally with the <code>ConfiguredAgentFactory</code> and individual agents get access to only those tools that they are configured to use. The factory is passed to the <code>AgentRegistry</code> extension. All configured agents are listed from the <code>AgentConfigurationSource</code> and created on the fly as and when needed. A summarized list of all configured agents is injected to the prompt sent to the model being used by the top-level agent. The top-level agent can then invoke any of the configured agents as tools to get work done.</p>"},{"location":"agent-registry.html#dependencies","title":"Dependencies","text":"<p>To use the agent registry and configured agents, you need to include the following dependencies in your project:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n    &lt;artifactId&gt;sentinel-ai-configured-agents&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre>"},{"location":"agent-registry.html#creating-an-agent-factory","title":"Creating an Agent Factory","text":"<p>Use the builder on the <code>ConfiguredAgentFactory</code> to create an agent factory.</p> <pre><code>final var agentFactory = ConfiguredAgentFactory.builder()\n        .httpToolboxFactory(...) // Optional, if you want to provide HTTP capabilities\n        .mcpToolboxFactory(...)  // Optional, if you want to provide MCP capabilities\n        .customToolBox(...)   // Optional, if you want to provide custom/local capabilities\n        .build();\n</code></pre>"},{"location":"agent-registry.html#agent-configuration-source","title":"Agent Configuration Source","text":"<p>In order for Sentinel AI to be able to build agents on the fly, it needs to read agent configurations from an <code>AgentConfigurationSource</code>. You can use <code>InMemoryAgentConfigurationSource</code> for testing or simple use cases where existing configurations can be populated at runtime or loaded from somewhere more permanent.</p> <pre><code>final var agentSource = new InMemoryAgentConfigurationSource();\n</code></pre>"},{"location":"agent-registry.html#agent-factory","title":"Agent Factory","text":"<p><code>ConfiguredAgentFactory</code> is used to create instances of configured agents on the fly. It needs to be provided with different toolboxes that agents can use based on their configured capabilities. ToolBoxes that can be completely configure from outside, for example <code>HTTP ToolBox</code> and <code>MCP ToolBox</code> are created on the fly using ToolBox Factories. </p><pre><code>final var agentFactory = ConfiguredAgentFactory.builder()\n        .httpToolboxFactory(...) // Optional, if you want to provide HTTP capabilities\n        .mcpToolboxFactory(...)  // Optional, if you want to provide MCP capabilities\n        .customToolBox(...)   // Optional, if you want to provide custom/local capabilities\n        .build();\n</code></pre><p></p>"},{"location":"agent-registry.html#agent-registry","title":"Agent Registry","text":"<p>The <code>AgentRegistry</code> extension is used to manage and provide access to configured agents. It needs to be provided with an <code>AgentConfigurationSource</code> to read agent configurations and an <code>ConfiguredAgentFactory</code> to create instances of configured agents.</p> <p></p><pre><code>final var agentRegistry = AgentRegistry.builder()\n        .agentConfigurationSource(agentSource) //Mandatory\n        .configuredAgentFactory(agentFactory::createAgent) //Mandatory\n        .build();\n</code></pre> The <code>AgentRegistry</code> extension can then be added to the top level <code>Agent</code> implementation.<p></p> <pre><code>final var topAgent = PlannerAgent.builder()\n                .setup(setup)\n                .extension(registry)\n                .build();\n\n// Interact with the planner agent as usual\nfinal var response = topAgent.executeAsync(AgentInput.&lt;String&gt;builder()\n                                                   .request(\"Summarize the story of War and Peace\")\n                                                   .build())\n        .join();\n</code></pre> <p>The <code>AgentRegistry</code> extension automatically injects a summarized list of all configured agents to the prompt sent to the model being used by the top-level agent. It also exposes tools for the planner to get details like I/O schema of these agents and to invoke them to get work done.</p> <p>Sample planner agent implementation</p> <p>The following is the trivial implementation of a planner agent that uses the agent registry extension to manage and invoke Configured Agents.</p> <pre><code>    public class PlannerAgent extends Agent&lt;String, String, PlannerAgent&gt; {\n        @Builder\n        public PlannerAgent(\n                @NonNull AgentSetup setup,\n                @Singular List&lt;AgentExtension&lt;String, String, PlannerAgent&gt;&gt; extensions) {\n            super(String.class,\n                  \"\"\"\n                          Your role is to perform complex tasks as specified by the user. You can achieve this by using\n                           the other agents.\n                          \"\"\",\n                  setup,\n                  extensions,\n                  Map.of());\n        }\n\n        @Override\n        public String name() {\n            return \"planner-agent\";\n        }\n    }\n</code></pre>"},{"location":"agent-registry.html#configuring-agents","title":"Configuring Agents","text":"<p>Agents can be configured using the <code>AgentConfiguration</code> class. Such agents need to be registered with the <code>AgentRegistry</code> by calling the <code>configureAgent</code> method. The registry in-turn invokes the <code>AgentConfigurationSource::save</code> method to  persist the configuration and the <code>ConfiguredAgentFactory</code> to create an instance of the agent on the fly as and when needed.</p> <pre><code>// Create agent configuration\nfinal var summarizerAgentConfig = AgentConfiguration.builder()\n        .agentName(\"Summarizer Agent\") //(1)!\n        .description(\"Summarizes input text\") //(2)!\n        .prompt(\"Provide a 140 character summary for the provided input text\") //(3)!\n        .inputSchema(JsonUtils.schemaForPrimitive(String.class, \"rawTextInput\", mapper)) //(4)!\n        .outputSchema(JsonUtils.schema(SummarizerAgentOutput.class)) //(5)!\n        .capability(AgentCapabilities.remoteHttpCalls(Map.of(\"weatherserver\", //(6)!\n                                                             Set.of(\"get_weather_for_location\"))))\n        .capability(AgentCapabilities.mcpCalls(Map.of(\"mcp\", Set.of(\"add\"))))\n        .build();\n\n// Register agent configuration with the registry\nagentRegistry.configureAgent(summarizerAgentConfig);\n</code></pre> <ol> <li>Name of the agent (Mandatory)</li> <li>Description of the agent (Mandatory)</li> <li>Prompt to be used by the agent (Mandatory)</li> <li>Input schema for the agent. (Optional, defaults to a simple string input schema)</li> <li>Output schema for the agent (Optional, defaults to a simple string output schema)</li> <li>Capabilities of the agent (Optional, defaults to no capabilities). See section on Tools for Configured Agents for more details.</li> </ol> <p>Schema generation</p> <p>You can use the <code>JsonUtils.schemaForPrimitive</code> and <code>JsonUtils.schema</code> utility functions to generate schema in the required format for primitive types/string and classes/records respectively.</p>"},{"location":"agent-registry.html#agent-configuration-parameters","title":"Agent Configuration Parameters","text":"<p>The following parameters can be configured using the <code>AgentConfiguration</code> builder.</p> Builder Parameter Mandatory Description agentName Yes Name of the agent to be configured. description Yes Detailed description of the agent. prompt Yes System prompt to be used for the agent. inputSchema No Input schema for the agent. Defaults to String if missing. outputSchema No Output schema for the agent. Defaults to String if missing. capabilities No Extra capabilities of the agent."},{"location":"agent-registry.html#code-based-agents","title":"Code-Based Agents","text":"<p>While many agents can be fully configured using JSON/YAML, you might need to register agents implemented entirely in Java. You can do this by extending the <code>RegisterableAgent</code> class and registering it with the <code>AgentRegistry</code>.</p> <pre><code>public class MyCustomAgent extends RegisterableAgent&lt;MyCustomAgent&gt; {\n    public MyCustomAgent(AgentSetup setup) {\n        super(AgentConfiguration.builder()\n                .agentName(\"custom-agent\")\n                .description(\"A custom agent implemented in Java\")\n                .build(),\n              setup,\n              List.of(),\n              Map.of());\n    }\n}\n\n// Registering the code-based agent\nagentRegistry.register(new MyCustomAgent(setup));\n</code></pre>"},{"location":"agent-registry.html#registry-tools","title":"Registry Tools","text":"<p>The <code>AgentRegistry</code> extension provides several tools that allow the parent agent to discover and interact with registered agents.</p> Tool Name Description Parameters <code>agent_registry_get_agent_metadata</code> Retrieves detailed metadata for a specific agent, including its I/O schema and description. <code>agentId</code> (String) <code>agent_registry_invoke_agent</code> Executes a specific agent with a provided JSON input and returns the structured response. <code>agentId</code> (String), <code>agentInput</code> (String) <p>Conditional Tool Exposure</p> <p>The <code>agent_registry_get_agent_metadata</code> tool is only exposed if the registry is configured with <code>AgentMetadataAccessMode.METADATA_TOOL_LOOKUP</code>. If set to <code>INCLUDE_IN_PROMPT</code> (default), agent metadata is injected directly into the facts, and this tool is removed to save on tool definition overhead.</p>"},{"location":"agent-registry.html#planner-worker-discovery","title":"Planner-Worker Discovery","text":"<p>The <code>AgentRegistry</code> extension facilitates a \"Planner-Worker\" architecture by automatically exposing registered agents as tools to the parent agent. </p> <ol> <li>Discovery via Facts: The registry injects a list of all available agents (their names and IDs) into the system prompt as \"Facts\".</li> <li>Metadata Lookup: If configured, the parent agent can use a tool to fetch the detailed I/O schema for a specific agent.</li> <li>Automated Tool Exposure: The registry provides an <code>invokeAgent</code> tool to the parent. When the parent LLM decides to delegate a task, it simply calls this tool with the target <code>agentId</code> and the required input.</li> </ol> <p>This mechanism allows Planner agents to dynamically discover and utilize any agent registered in the system without requiring explicit code changes to the Planner itself.</p>"},{"location":"agent-registry.html#loading-agent-configurations-from-file","title":"Loading Agent configurations from file","text":"<p>Agent Configurations can be loaded into the registry directly into registry from serialized JSON using the following functions:</p> <ul> <li><code>loadAgentsFromContent(byte[] content)</code> - Load agent configurations from serialized JSON content.</li> <li><code>loadAgentsFromFile(final String agentConfig)</code> - Load agent configurations from a file containing serialized JSON</li> </ul> <p>Both methods return the list of agents that were loaded into the registry.</p> <pre><code>// Load agent configurations from file\nfinal var agents = agentRegistry.loadAgentsFromFile(\"path/to/agent_config.json\");\n</code></pre>"},{"location":"agent-registry.html#agent-configuration-file-format","title":"Agent Configuration File Format","text":"<p>Sample file format can be found below: </p><pre><code>[\n  {\n    \"agentName\": \"All-in-One Agent\", //(1)!\n    \"description\": \"Agent with HTTP, MCP, and Custom Tool capabilities.\", //(2)!\n    \"prompt\": \"Use all available tools to answer the query.\", //(3)!\n    \"inputSchema\": { //(4)!\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"required\": [\n        \"location\"\n      ],\n      \"properties\": {\n        \"location\": {\n          \"description\": \"Location to know weather for\",\n          \"type\": \"string\"\n        }\n      }\n    },\n    \"outputSchema\": { //(5)!\n      \"type\": \"object\",\n      \"properties\": {\n        \"condition\": {\n          \"type\": \"string\"\n        },\n        \"temperature\": {\n          \"type\": \"string\"\n        }\n      },\n      \"required\": [\n        \"condition\",\n        \"temperature\"\n      ],\n      \"additionalProperties\": false\n    },\n    \"capabilities\": [ //(6)!\n      {\n        \"type\": \"REMOTE_HTTP_CALLS\", //(7)!\n        \"selectedTools\": { //(8)!\n          \"weatherserver\": [ //(9)!\n            \"get_weather_for_location\" //(10)!\n          ]\n        }\n      },\n      {\n        \"type\": \"MCP\", //(11)!\n        \"selectedTools\": { //(12)!\n          \"mcp\": [ //(13)!\n            \"add\", //(14)!\n            \"subtract\"\n          ]\n        }\n      },\n      {\n        \"type\": \"CUSTOM_TOOLS\", //(15)!\n        \"selectedTools\": [//(16)!\n          \"getWeather\",\n          \"doSomethingCustom\"\n        ]\n      }\n    ]\n  },\n  ... //more agents\n]\n</code></pre><p></p> <ol> <li>Name of the agent (Mandatory)</li> <li>Description of the agent (Mandatory)</li> <li>Prompt to be used by the agent (Mandatory)</li> <li>Input schema for the agent. (Optional, defaults to a simple string input schema)</li> <li>Output schema for the agent (Optional, defaults to a simple string output schema)</li> <li>Capabilities of the agent (Optional, defaults to no capabilities).</li> <li>Fixed for Remote HTTP calls.</li> <li>HTTP tools exposed to this agent.</li> <li>Name of HTTP upstream as specified in HTTPToolboxFactory configuration.</li> <li>Set of tools selected from this upstream.</li> <li>Fixed for MCP calls.</li> <li>MCP tools exposed to this agent.</li> <li>Name of MCP upstream as specified when configuring MCP servers in MCPToolBoxFactory.</li> <li>Set of tools selected from this upstream.</li> <li>Fixed for Custom/local tools.</li> <li>Set of custom/local tools exposed to this agent as explained in Using Custom Tools.</li> </ol>"},{"location":"agent-registry.html#tools-for-configured-agents","title":"Tools for Configured Agents","text":"<p>Configured agents can use tools from different sources. Sentinel AI provides built-in support for the following tool sources:</p> <ul> <li>HTTP ToolBox: Tools that make remote HTTP calls to upstream services. Check the section on   HTTP ToolBox for more details.</li> <li>MCP ToolBox: Tools that make calls to MCP servers. Check the section on   MCP ToolBox for more details.</li> <li>Custom ToolBox: Tools that are implemented in local code and registered with the agent factory.</li> </ul> <pre><code>flowchart TD\n    USER[\"User/Client\"]\n    TOP_AGENT[\"Planner/Orchestrator Agent\"]\n    subgraph ToolSources[\"Tool Sources\"]\n        HTTP[HTTP Tool Box Factory]\n        MCP[MCP Tool Box Factory]\n        CUSTOM[Custom Tool Box]\n    end\n    AGENT_FACTORY[\"Agent Factory\"]\n    REGISTRY[\"Agent Registry (Extension)\"]\n    subgraph Agents[\"Configured Agents\"]\n        AGENT1[ConfiguredAgent A]\n        AGENT2[ConfiguredAgent B]\n    end\n\n    USER -- Requests Work --&gt; TOP_AGENT\n    TOP_AGENT -- Calls agents using tool calls --&gt; REGISTRY --&gt; AGENT_FACTORY -- Creates on the fly --&gt; Agents\n    ToolSources -- Globally Registered Tools --&gt; AGENT_FACTORY\n    Agents -- Uses Tools From --&gt; ToolSources\n    TOP_AGENT -.-&gt; Agents</code></pre> <p>When using Configured Agents and Agent Registry, tools from remote HTTP sources, MCP servers and local code are globally registered to the AgentRegistry itself. Once registered, such tools can be used by individual agents as configured using <code>AgentCapability</code> when configuring it. This prevents pollution of the prompts sent to models being used individual agents.</p>"},{"location":"agent-registry.html#making-remote-http-calls","title":"Making remote HTTP calls","text":"<p>As we have seen in the section on HTTP ToolBox, Sentinel AI provides a flexible way to configure and expose HTTP API calls to upstream services as parameterized tools that agents can use. The <code>HttpToolboxFactory</code> is used to create instances of <code>HttpToolbox</code> on the fly as and when needed.</p> <pre><code>//Create HTTP Tool Source\nfinal var toolSource = InMemoryHttpToolSource.builder() //Create tool source\n                .mapper(MAPPER)\n                .build();\n//Bulk Load tools from YAML file\nHttpToolReaders.loadToolsFromYAML(Paths.get(\"http-tools.yaml\"), toolSource);\n\n//Register custom HTTP tools to toolSource\ntoolSource.registerTool(\"my-service\", ...);\n\n//Add tools to toolSource any other way you want\n\n//Create OkHttpClient instance to make the actual HTTP calls\nfinal var okHttpClient = new OkHttpClient.Builder()\n                ... //Custom configurations\n                .build();\n\n//Create and pass the HttpToolboxFactory to ConfiguredAgentFactory\nfinal var agentFactory = ConfiguredAgentFactory.builder()\n                .httpToolboxFactory(HttpToolboxFactory.builder() //All params mandatory\n                                            .toolConfigSource(toolSource)\n                                            .okHttpClient(okHttpClient)\n                                            .objectMapper(objectMapper)\n                                            .upstreamResolver(UpstreamResolver.direct())\n                                            .build())\n                .build();\n</code></pre> <p>OkHttp Client Provider</p> <p>The <code>HttpToolboxFactory</code> class provides another builder <code>httpClientProvidingBuilder</code> which lets you configure a provider function that resolves to a specific instance of OkHttpClient depending on the upstream name.</p> <pre><code> HttpToolboxFactory.httpClientProvidingBuilder()\n    .okHttpClientProvider(upstream -&gt; myClientRegistery.getClient(upstream)) //or so on\n    ...\n    .build()\n</code></pre> <p>Once configured, tools from this factory can be used by configured agents by using the  <code>AgentCapabilities.remoteHttpCalls</code> capability.</p> <pre><code>final var weatherAgentConfig = AgentConfiguration.builder()\n                //Standard config\n                ...\n                //Add http tool call capabilites\n                .capability(AgentCapabilities.remoteHttpCalls(\n                        Map.of(\"userservice\", //Upstream name\n                               Set.of(\"get_user_name\", \"get_location_from_user\"),  //Set of tools from this upstream\n                               \"weatherserver\", //Upstream name\n                               Set.of(\"get_weather_for_location\")  //Set of tools from upstream\n                        )))\n                .build();\n</code></pre>"},{"location":"agent-registry.html#using-tools-from-mcp-servers","title":"Using tools from MCP servers","text":"<p>Similar to <code>HttpToolboxFactory</code>, the <code>McpToolboxFactory</code> is used to create instances of <code>McpToolbox</code> on the fly as and when needed. check the section on MCP ToolBox for more details on how to use MCP servers with Sentinel AI.</p> <pre><code>// Load MCP json config from file\nfinal var mcpToolboxFactory = MCPToolBoxFactory.builder()\n                                           .objectMapper(MAPPER)\n                                           .build();\n\n// (Optionally) Load MCP server details from mcp JSON file\nmcpToolboxFactory.loadFromFile(\"/path/to/mcp_config.json\");\n\n// (Optionally) Register clients for specific upstreams programmatically\nmcpToolboxFactory.registerMcpClient(\"my-upstream\", mcpClient);\n\n// Create agent factory and pass the MCP toolbox factory\nfinal var agentFactory = ConfiguredAgentFactory.builder()\n        .mcpToolboxFactory(mcpToolboxFactory)\n        .build();\n</code></pre> <p>Custom MCP Client resolution</p> <p>You can also provide a custom MCP client resolver function to the <code>McpToolboxFactory</code> builder that can resolve to a specific instance of <code>McpClient</code> depending on the upstream name. This is useful when you have multiple MCP clients to connect to different MCP servers and for some reason the registry won't work for you.</p> <pre><code> MCPToolBoxFactory.builder()\n    .mcpClientProvider(upstream -&gt; myMcpClientRegistery.getClient(upstream)) //or so on\n    ...\n    .build()\n</code></pre> <p>Once configured, tools from this factory can be used by configured agents by using the <code>AgentCapabilities.mcpCalls</code> capability.</p> <pre><code>final var mathAgentConfig = AgentConfiguration.builder()\n                //Standard config, http tool boc factory etc\n                ...\n                //Add mcp tool call capabilites\n                .capability(AgentCapabilities.mcpCalls(Map.of(\n                        \"metricservice\", // Upstream/MCP server name as specified in MCP JSON config or during client registration\n                        Set.of(\"load_timeseries\"), // Set of tools from this MCP server\n                        \"mathservice\", // Upstream/MCP server name\n                        Set.of(\"multiply\", \"divide\") // Set of tools from this MCP server\n                    )));\n                .build();\n</code></pre>"},{"location":"agent-registry.html#using-custom-tools","title":"Using Custom Tools","text":"<p>Custom tools are those that are implemented in local code and registered with the <code>ConfiguredAgentFactory</code>. Custom tools can be used to perform tasks that are specific to your application or domain and cannot be easily achieved using remote HTTP calls or MCP calls. Custom tools can be anything from simple utility functions to complex business logic implementations. Custom tools are registered globally with the <code>ConfiguredAgentFactory</code> and individual agents get access to only those tools that they are configured to use using the <code>AgentCapabilities.customToolCalls</code> capability.</p> <pre><code>//Define tools as usual\n@Tool(\"Provides the weather for a location\")\npublic String getWeather(@JsonPropertyDescription(\"Name of the city to get weather for\") final String city) {\n    return \"\"\"\n            {\n            \"location\" : \"Bangalore\",\n            \"temperature\" : \"33 centigrade\",\n            \"condition\" : \"sunny\"\n            }\n            \"\"\";\n}\n\n// Create a global custom tool box and register custom tools\nfinal var globalCustomToolBox = CustomToolBox.builder()\n                                       .name(\"custom\")\n                                       .build();\n\n// Register tools\nglobalCustomToolBox.registerToolsFromObject(this);\n\n// Register the custom tool box with the agent factory\nfinal var agentFactory = ConfiguredAgentFactory.builder()\n        .customToolBox(globalCustomToolBox)\n        .build();\n</code></pre> <p>Registering tools of various types</p> <p>The <code>CustomToolBox</code> class provides multiple ways to register tools.</p> <p>Once the tools are registered globally with the <code>ConfiguredAgentFactory</code>, they can be used by configured agents by using the <code>AgentCapabilities.customToolCalls</code> capability.</p> <pre><code>// Create agent configured factory and register custom tools\nfinal var agentConfig = AgentConfiguration.builder()\n                //Standard config, http tool boc factory etc\n                ...\n                //Add custom tool call capabilites\n                .capability(AgentCapabilities.customToolCalls(Set.of(\"getWeather\", \"getName\")))\n                .build();\n</code></pre>"},{"location":"agents.html","title":"Agents","text":""},{"location":"agents.html#agent-basics","title":"Agent Basics","text":"<p>The core abstraction of Sentinel AI is the <code>Agent</code> class. The <code>Agent</code> class is a generic class that takes three type parameters:</p> <ul> <li><code>R</code>: The type of the request object that the agent receives. This can be a string or any other complex Java type.</li> <li><code>T</code>: The type of the response object that the agent returns. This can also be a string or any other complex Java type.</li> <li><code>A</code>: The agent subtype. This is the class you are currently implementing.</li> </ul>"},{"location":"agents.html#request-and-response-type-parameters","title":"Request and Response Type parameters","text":"<p>Sentinel supports sending both text and objects as input and output. The type parameters <code>R</code> and <code>T</code> can be any Java type, including strings, lists, maps, or custom objects. The only requirement is that the types must be serializable to JSON.</p> <p>Sentinel will generate schema for the type parameters and pass is to the model to ensure requests are interpreted correctly and responses are generated properly.</p> <p>Use <code>@JsonClassDescription</code> and <code>@JsonPropertyDescription</code> liberally</p> <p>Use the <code>@JsonClassDescription</code> and <code>@JsonPropertyDescription</code> annotations to provide copious amounts of documentation on the classes and their members wherever they are used, be it as request type, response type, tool parameters and so on. This is added to the generated schema. A lot of the accuracy of the agent will finally depend on the amount of information you provide to the model. The more information you provide, the better the model will be able to interpret the request properly and generate the correct and relevant response.</p> <p>Sample request type would be like the following:</p> BookInfo.java<pre><code>@JsonClassDescription(\"Information about the book to be summarized\")\npublic record BookInfo(\n        @JsonPropertyDescription(\"Unique ID for the book\") String isbn,\n        @JsonPropertyDescription(\"Title of the book\") String title\n) {\n}\n</code></pre> <p>Similarly, the response type can be a complex object as well. For example, if you are implementing a book summarizer, a sample response can be like the following:</p> BookSummary.java<pre><code>@JsonClassDescription(\"Summary of the book\")\npublic record BookSummary(\n        @JsonPropertyDescription(\"Unique ID for the book\") String isbn,\n        @JsonPropertyDescription(\"Summary of the book\") String summary,\n        @JsonPropertyDescription(\"Topics discussed in the book\") List&lt;String&gt; topics\n) {\n}\n</code></pre>"},{"location":"agents.html#instantiating-a-model","title":"Instantiating a model","text":"<p>The <code>Model</code> class is a generic abstraction for an LLM model used by an agent. A concrete subclass of the Model needs to be instantiated for usage in the agent.</p> <p>Currently, we support only OpenAI API compliant model endpoints. The corresponding implementation of <code>Model</code> for this is the <code>SimpleOpenAIModel</code> class. The class is available in the <code>sentinel-ai-models-simple-openai</code> module.</p> <p>The module needs to be added to the project dependencies as follows:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n    &lt;artifactId&gt;sentinel-ai-models-simple-openai&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>This will add the required dependencies to instantiate the model with the SimpleOpenAI client library. The library itself is very flexible, and you should read the documentation for the library to understand how to use it. The model can be instantiated as follows:</p> <pre><code>final var model = new SimpleOpenAIModel&lt;&gt;(\n        \"gpt-4o\",\n        SimpleOpenAI.builder()\n                .baseUrl(EnvLoader.readEnv(\"OPENAI_ENDPOINT\"))\n                .apiKey(EnvLoader.readEnv(\"OPENAI_API_KEY\"))\n                .objectMapper(objectMapper)\n                .clientAdapter(new OkHttpClientAdapter(httpClient))\n                .build(),\n        objectMapper\n);\n</code></pre> <p>Type parameter for <code>SimpleOpenAIModel</code></p> <p>The <code>SimpleOpenAIModel</code> is a generic class. The type is inferred from the type of the model. Leave it as <code>&lt;&gt;</code>.</p> <p>Endpoint and api key</p> <p>The <code>OPENAI_ENDPOINT</code> and <code>OPENAI_API_KEY</code> are environment variables that need to be set in the system. The <code>EnvLoader</code> class is a utility class that loads the environment variables. You can use any other method to load the environment variables as well.</p>"},{"location":"agents.html#agent-setup","title":"Agent Setup","text":"<p>The <code>AgentSetup</code> class is a configuration class that is used to configure the agent. The class is available in the core library itself and can be used to set a variety of settings for the agent. The class provides a builder to allow to set only the required parameters and will default whatever it can if not provided.</p> <p>AgentSetup object needs to be passed at startup. However, if all parameters are not known or some of them need to be dynamic, a setup object can be passed as parameter to the <code>execute*</code> methods as well.</p>"},{"location":"agents.html#available-settings","title":"Available Settings","text":"<p>Here are all available settings for the <code>AgentSetup</code> class:</p> Setting Type Description <code>mapper</code> <code>ObjectMapper</code> The object mapper to use for serialization/deserialization. If not provided, a default one will be created. <code>model</code> <code>Model</code> The LLM to be used for the agent. This can be provided at runtime. If not provided, an error will be thrown. <code>modelSettings</code> <code>ModelSettings</code> The settings for the model. This can be provided at runtime. If not provided, an error will be thrown. <code>executorService</code> <code>ExecutorService</code> The executor service to use for running the agent. If not provided, a default cached thread pool will be created. <code>eventBus</code> <code>EventBus</code> The event bus to be used for the agent. If not provided, a default event bus will be created. <code>outputGenerationMode</code> <code>OutputGenerationMode</code> Output generation mode to use for this model. Can be <code>TOOL_BASED</code> (default) or <code>STRUCTURED_OUTPUT</code>. Typically, other than OpenAI models, it is safer to leave it at the default <code>TOOL_BASED</code> mode. <code>outputGenerationTool</code> <code>UnaryOperator&lt;String&gt;</code> A function that the model can use to generate the JSON string output. If not provided (recommended), Sentinel AI will use it's built in tool if the <code>outputGenerationMode</code> is set to <code>TOOL_BASED</code> <code>retrySetup</code> <code>RetrySetup</code> Retry setup to use for model calls. If not provided, default setup will be added. <p>Required parameters</p> <ul> <li>The <code>model</code>, and <code>modelSettings</code> are required parameters. If not provided, an error will be thrown. However, it is   possible that model etc is not known during agent creation. In that case, the parameters can be provided as part of   the <code>execute*</code> methods. If neither is available, exception will be provided at runtime.</li> <li>All the other parameters are optional. If not provided, a default one will be created/provided.</li> </ul>"},{"location":"agents.html#model-settings","title":"Model Settings","text":"<p>A variety of settings can be set for the model. The <code>ModelSettings</code> class is a configuration class that is used to configure the model. The class is available in the core library itself and provides a builder.</p> Setting Type Description <code>maxTokens</code> <code>Integer</code> Maximum number of tokens to generate. <code>temperature</code> <code>Float</code> Amount of randomness to inject in output. Lower values make the output more predictable. <code>topP</code> <code>Float</code> Probabilistic sum of tokens to consider for each subsequent token. Range: 0-1. <code>timeout</code> <code>Duration</code> Timeout for model calls. <code>parallelToolCalls</code> <code>Boolean</code> Whether to call tools in parallel or not. <code>seed</code> <code>Integer</code> Seed for random number generator to make output more predictable. <code>presencePenalty</code> <code>Float</code> Penalty for adding new tokens based on their presence in the output so far. <code>frequencyPenalty</code> <code>Float</code> Penalty for adding new tokens based on how many times they have appeared in the output so far. <code>logitBias</code> <code>Map&lt;String, Integer&gt;</code> Controls the likelihood of specific tokens being generated."},{"location":"agents.html#model-specific-options","title":"Model Specific Options","text":"<p>Some models support additional configuration options that are not part of the standard <code>ModelSettings</code>. For example, <code>SimpleOpenAIModel</code> supports <code>SimpleOpenAIModelOptions</code>.</p>"},{"location":"agents.html#token-counting-configuration","title":"Token Counting Configuration","text":"<p>You can tune how Sentinel AI estimates token usage for OpenAI models by providing a <code>TokenCountingConfig</code>. This is useful for adjusting for specific prompt formats or model-specific overheads.</p> <pre><code>final var tokenConfig = TokenCountingConfig.builder()\n        .messageOverHead(3) // Overhead tokens per message\n        .nameOverhead(1)    // Overhead tokens if 'name' is provided in message\n        .assistantPrimingOverhead(3) // Tokens added at the end of the prompt to prime assistant\n        .formattingOverhead(10) // Overhead for structured tool arguments\n        .build();\n\nfinal var modelOptions = SimpleOpenAIModelOptions.builder()\n        .tokenCountingConfig(tokenConfig)\n        .toolChoice(SimpleOpenAIModelOptions.ToolChoice.AUTO)\n        .build();\n\nfinal var model = new SimpleOpenAIModel&lt;&gt;(\n        \"gpt-4o\",\n        client,\n        objectMapper,\n        modelOptions // Pass options here\n);\n</code></pre>"},{"location":"agents.html#retry-setup","title":"Retry Setup","text":"<p>The <code>RetrySetup</code> class is a configuration class that is used to configure the retry mechanism for model calls.</p> Setting Type Description <code>totalAttempts</code> <code>int</code> Total number of attempts to make. This includes the successful attempts. <code>delayAfterFailedAttempt</code> <code>Duration</code> Delay after a failed attempt before retrying. <code>retriableErrorTypes</code> <code>Set&lt;ErrorTypes&gt;</code> Specific error types to retry on. If not provided, a pre-defined set of error types are retried. See Error Handling for details. <p>### Sample setup</p> <p>Sample code for creating settings for an agent:</p> <pre><code>final var agentSetup = AgentSetup.builder()\n        .model(model)\n        .mapper(objectMapper)\n        .modelSettings(ModelSettings.builder()\n                               .temperature(0.1f)\n                               .timeout(Duration.ofSeconds(10))\n                               .seed(1)\n                               .build())\n        .build();\n</code></pre>"},{"location":"agents.html#creating-an-agent","title":"Creating an agent","text":"<p>To create an agent, you need to do the following:</p> <ul> <li>Implement the <code>Agent</code> interface with the appropriate request and response type parameters</li> <li>Provide a system prompt</li> <li>Pass a setup object to the agent</li> <li>There are other parameters we shall explore in subsequent sections</li> </ul> <p>Continuing with the example, we want to create an agent that can summarize books. Code for such an agent would look something like this:</p> BookSummarizingAgent.java<pre><code>public class BookSummarizingAgent extends Agent&lt;BookInfo, BookSummary, BookSummarizingAgent&gt; {\n    public BookSummarizingAgent(AgentSetup setup) {\n        super(BookSummary.class,\n              \"You are an expert in summarizing books. You will be provided with the title and ISBN of a book.\" +\n                      \" You need to summarize the book and provide the topics discussed in the book.\",\n              setup,\n              List.of(),\n              Map.of());\n    }\n\n    @Override\n    public String name() {\n        return \"book-summarizer\";\n    }\n}\n</code></pre>"},{"location":"agents.html#the-agentinput-class","title":"The <code>AgentInput</code> class","text":"<p>Sentinel agent <code>execute*</code> requests can take multiple parameters along with the core request(user prompt). The <code>AgentInput</code> class wraps all parameters and provides a builder allowing users to easily send or skip additional parameters.</p> Property Type Description <code>request</code> <code>R</code> Request object. This is a required parameter. <code>facts</code> <code>List&lt;FactList&gt;</code> List of facts to be passed to the agent. This is passed to LLM as 'knowledge' in the system prompt. <code>requestMetadata</code> <code>AgentRequestMetadata</code> Metadata for the request. <code>oldMessages</code> <code>List&lt;AgentMessage&gt;</code> List of old messages to be sent to the LLM for this run. If set to <code>null</code>, messages are generated and consumed by the agent in this session. <code>agentSetup</code> <code>AgentSetup</code> Setup for the agent. Overrides runtime setup. If set to <code>null</code>, the setup provided during agent creation is used. Fields provided at runtime take precedence."},{"location":"agents.html#the-agentoutput-class","title":"The <code>AgentOutput</code> class","text":"<p>The return type for all <code>execute*</code> methods is <code>AgentOutput</code> which is a generic class typed with the response type <code>T</code>. The class contains the following fields:</p> Member Type Description <code>data</code> <code>T</code> The output of the agent, typed to the required response type. Null in case of errors. <code>newMessages</code> <code>List&lt;AgentMessage&gt;</code> New messages generated by the agent. Empty in case of errors. <code>allMessages</code> <code>List&lt;AgentMessage&gt;</code> All messages generated by the agent, including the new messages. <code>usage</code> <code>ModelUsageStats</code> Usage statistics for the model. <code>error</code> <code>SentinelError</code> Error in case of failure or a success object otherwise."},{"location":"agents.html#model-usage-statistics","title":"Model Usage Statistics","text":"<p>The <code>ModelUsageStats</code> class tracks usage statistics for a model, including token usage and request details.</p> Member Type Description <code>requestsForRun</code> <code>int</code> Number of requests made for this run. <code>toolCallsForRun</code> <code>int</code> Number of tool calls made for this run. <code>requestTokens</code> <code>int</code> Number of request/prompt tokens used in this run. Equivalent to the \"prompt_tokens\" parameter in OpenAI usage. <code>responseTokens</code> <code>int</code> Number of completion/response tokens used in this run. Equivalent to the \"completion_tokens\" parameter in OpenAI usage. <code>totalTokens</code> <code>int</code> Total tokens used in the whole run. Should generally equal <code>requestTokens + responseTokens</code>. <code>requestTokenDetails</code> <code>PromptTokenDetails</code> Token usage details for prompts. <code>responseTokenDetails</code> <code>ResponseTokenDetails</code> Token usage details for responses. <code>details</code> <code>Map&lt;String, Integer&gt;</code> Additional details about token usage."},{"location":"agents.html#prompttokendetails-class","title":"<code>PromptTokenDetails</code> Class","text":"<p>The <code>PromptTokenDetails</code> class provides detailed information about tokens used in prompts.</p> Member Type Description <code>cachedTokens</code> <code>int</code> Number of cached tokens present in the prompt. <code>audioTokens</code> <code>int</code> Number of audio input tokens present in the prompt."},{"location":"agents.html#responsetokendetails-class","title":"<code>ResponseTokenDetails</code> Class","text":"<p>The <code>ResponseTokenDetails</code> class provides detailed information about tokens used in responses.</p> Member Type Description <code>reasoningTokens</code> <code>int</code> Number of tokens generated by the model for reasoning. <code>acceptedPredictionTokens</code> <code>int</code> Number of tokens in the prediction that appeared in the completion when using predicted outputs. <code>rejectedPredictionTokens</code> <code>int</code> Number of tokens in the prediction that did not appear in the completion when using predicted outputs. <code>audioTokens</code> <code>int</code> Number of audio input tokens generated by the model."},{"location":"agents.html#using-the-agent","title":"Using the agent","text":"<p>The agent can be invoked by calling any of the provided <code>execute*</code> methods.</p> <ul> <li><code>executeAsync()</code> method and it's overloads can be used to (you guessed it) invoke the LLM asynchronously. It returns a   <code>CompletableFuture</code> object which can be used to get the result when it is available.</li> <li><code>execute()</code> method and it's overloads can be used to invoke the LLM synchronously. It returns the result directly.</li> </ul> <p>In either case, the agent will be invoked with the provided request object and the response object will be returned along with errors and usage information.</p> <pre><code>final var agent = new BookSummarizingAgent(agentSetup);\n\nfinal var response = agent.execute(\n        AgentInput.&lt;BookInfo&gt;builder()\n                .request(new BookInfo(\"978-0393096729\", \"War and Peace\"))\n                .build());\nSystem.out.println(objectMapper.writerWithDefaultPrettyPrinter()\n                               .writeValueAsString(response.getData()));\n</code></pre> <p>Output from the above would be something like:</p> <pre><code>{\n  \"isbn\" : \"978-0393096729\",\n  \"summary\" : \"\\\"War and Peace\\\" is a historical novel by Leo Tolstoy that intertwines the lives of several families during the Napoleonic Wars in the early 19th century. The narrative explores themes of love, fate, and the impact of war on society. It follows characters such as Pierre Bezukhov, Prince Andrei Bolkonsky, and Natasha Rostova as they navigate personal struggles and the broader historical events that shape their lives. The novel delves into the philosophical questions of history and the nature of power, ultimately portraying the complexity of human experience amidst the chaos of war.\",\n  \"topics\" : [ \"Historical fiction\", \"Napoleonic Wars\", \"Russian society\", \"Philosophy of history\", \"Love and relationships\", \"Fate and free will\", \"Family dynamics\", \"War and its consequences\" ]\n}\n</code></pre>"},{"location":"agents.html#request-metadata","title":"Request Metadata","text":"<p>Sometimes it is important to maintain context of the conversation. For example, if you are building a chat agent, you may want to keep track of the session or the user the conversation is happening with. SentinelAI provides the <code>AgentRequestMetadata</code> class for this purpose. The metadata class also provides the option to send back the <code>ModelUsageStats</code> object from previous calls. This can be used to keep track of the usage of the model and the agent across calls. If provided, the agent will merge the usage from current execution to the provided usage stats object.</p> <p>Request metadata passed to model</p> <p>The request metadata passed to execute calls are serialized and passed to the LLM as part of the structured system prompt.</p> Property Type Description <code>sessionId</code> <code>String</code> Session ID for the current conversation. This is passed to LLM as additional data in the system prompt. <code>userId</code> <code>String</code> A User ID for the user the agent is having the current conversation with. This is passed to LLM as additional data in the system prompt. <code>customParams</code> <code>Map&lt;String, Object&gt;</code> Any other custom parameters that need to be passed to the agent or the tools being invoked by the agent. This is passed to LLM as additional data in the system prompt. <code>usageStats</code> <code>ModelUsageStats</code> Global usage stats object that can be used to track usage of the model across execute calls. <p>Note</p> <p>Request metadata is optional and passing <code>null</code> for this param is acceptable.</p>"},{"location":"agents.html#prompts","title":"Prompts","text":"<p>Sentinel AI has some special handling to improve LLM performance for agentic use cases both for system and user prompts.</p>"},{"location":"agents.html#system-prompts","title":"System Prompts","text":"<p>SentinelAI converts the system prompt in an XML format for easy parsing by the LLM. The string or object passed as the system prompt to the agent is passed in a tag called <code>&lt;role&gt;</code>. Other information such as tools, properties from request metadata as well as facts and additional tasks from the registered extensions are added to the prompt as well.</p> <p>Serializability requirements</p> <p>The system prompt needs to be serializable to XML. If not, an error will be thrown.</p> <p>Structured prompts</p> <p>We recommend passing the system prompt as a structured object. This will help the LLM understand the context better and speed up processing as well. Check the <code>SystemPrompt</code> class for tips on how to use different jackson annotations to make system prompts serialize correctly.</p> Sample system prompt generated by SentinelAI<pre><code>&lt;?xml version='1.1' encoding='UTF-8'?&gt;\n&lt;SystemPrompt&gt;\n    &lt;coreInstructions&gt;Your main job is to answer the user query as provided in user prompt in the `user_input` tag.\n        Perform the provided secondary tasks as well and populate the output in designated output field for the task.\n        Use the provided knowledge and facts to enrich your responses and avoid unnecessary tool calls.\n    &lt;/coreInstructions&gt;\n    &lt;primaryTask&gt;\n        &lt;role&gt;greet the user&lt;/role&gt; &lt;!--(1)!--&gt;\n        &lt;tools&gt; &lt;!--(2)!--&gt;\n            &lt;tool&gt;\n                &lt;name&gt;test_tool_box_get_location_for_user&lt;/name&gt;\n                &lt;description&gt;Get location for user&lt;/description&gt;\n            &lt;/tool&gt;\n            &lt;tool&gt;\n                &lt;name&gt;simple_agent_get_name&lt;/name&gt;\n                &lt;description&gt;Get name of user&lt;/description&gt;\n            &lt;/tool&gt;\n            &lt;tool&gt;\n                &lt;name&gt;test_tool_box_get_weather_today&lt;/name&gt;\n                &lt;description&gt;Get weather today&lt;/description&gt;\n            &lt;/tool&gt;\n            &lt;tool&gt;\n                &lt;name&gt;simple_agent_get_salutation&lt;/name&gt;\n                &lt;description&gt;Get salutation for user&lt;/description&gt;\n            &lt;/tool&gt;\n        &lt;/tools&gt;\n    &lt;/primaryTask&gt;\n    &lt;secondaryTasks&gt; &lt;!--(3)!--&gt;\n        &lt;secondaryTask&gt;\n            &lt;instructions&gt;\n                &lt;tasks&gt;\n                    &lt;task&gt;\n                        &lt;objective&gt;EXTRACT MEMORY FROM MESSAGES AND POPULATE `memoryOutput` FIELD&lt;/objective&gt;\n                        &lt;outputField&gt;memoryOutput&lt;/outputField&gt;\n                        &lt;instructions&gt;How to extract different memory types:\n                            - SEMANTIC: Extract fact about the session or user or any other subject\n                            - EPISODIC: Extract a specific event or episode from the conversation\n                            - PROCEDURAL: Extract a procedure as a list of steps or a sequence of actions that you can\n                            use later\n                        &lt;/instructions&gt;\n                        &lt;additionalInstructions&gt;IMPORTANT INSTRUCTION FOR MEMORY EXTRACTION:\n                            - Do not include non-reusable information as memories.\n                            - Extract as many useful memories as possible\n                        &lt;/additionalInstructions&gt;\n                        &lt;tools&gt;\n                            &lt;tool&gt;\n                                &lt;name&gt;agent_memory_extension_find_procedural_memory&lt;/name&gt;\n                                &lt;description&gt;Find procedural memory about any topic from the store&lt;/description&gt;\n                            &lt;/tool&gt;\n                        &lt;/tools&gt;\n                    &lt;/task&gt;\n                &lt;/tasks&gt;\n            &lt;/instructions&gt;\n        &lt;/secondaryTask&gt;\n    &lt;/secondaryTasks&gt;\n    &lt;additionalData&gt; &lt;!--(4)!--&gt;\n        &lt;sessionId&gt;s1&lt;/sessionId&gt;\n        &lt;userId&gt;ss&lt;/userId&gt;\n    &lt;/additionalData&gt;\n    &lt;knowledge&gt; &lt;!--(5)!--&gt;\n        &lt;facts&gt;\n            &lt;description&gt;Memories about current session&lt;/description&gt;\n            &lt;fact&gt;\n                &lt;name&gt;UserName&lt;/name&gt;\n                &lt;content&gt;The user's name is Santanu.&lt;/content&gt;\n            &lt;/fact&gt;\n            &lt;fact&gt;\n                &lt;name&gt;UserLocation&lt;/name&gt;\n                &lt;content&gt;The user is located in Bangalore.&lt;/content&gt;\n            &lt;/fact&gt;\n            &lt;fact&gt;\n                &lt;name&gt;WeatherToday&lt;/name&gt;\n                &lt;content&gt;The weather in Bangalore today is sunny.&lt;/content&gt;\n            &lt;/fact&gt;\n        &lt;/facts&gt;\n    &lt;/knowledge&gt;\n&lt;/SystemPrompt&gt;\n</code></pre> <ol> <li>System prompt provided to the <code>Agent</code> class constructor.</li> <li>Tools registered with and discovered by the agent.</li> <li>Secondary tasks provided by extensions</li> <li>Request metadata passed to the agent</li> <li>Facts provided by extensions and client</li> </ol>"},{"location":"agents.html#user-prompts","title":"User prompts","text":"<p>The mandatory <code>request</code> property passed in the <code>AgentInput&lt;R&gt;</code> parameter to the <code>execute*</code> methods is converted to a structured XML object and wrapped in <code>&lt;user_input&gt;</code> tag.</p> <p>For example, for the book summarizer agent, the provided <code>BookInfo</code> object is sent to the LLM as follows: </p><pre><code>&lt;user_input&gt;\n  &lt;isbn&gt;978-0393096729&lt;/isbn&gt;\n  &lt;title&gt;War and Peace&lt;/title&gt;\n&lt;/user_input&gt;\n</code></pre><p></p> <p>Original input request for the above would be something like: </p><pre><code>agent.execute(\n      AgentInput.&lt;BookInfo&gt;builder()\n              .request(new BookInfo(\"978-0393096729\", \"War and Peace\"))\n              .build());\n</code></pre><p></p>"},{"location":"agents.html#customizing-agent-behaviour","title":"Customizing Agent Behaviour","text":"<p>The <code>Agent</code> class constructor allows you to customize agent behaviour extensively by passing additional parameters. This enables you to control how your agent handles tools, extensions, validation, and error handling.</p>"},{"location":"agents.html#constructor-parameters","title":"Constructor Parameters","text":"Parameter Type Mandatory Description outputType Class&lt;T&gt; Yes The class of the agent's output type. systemPrompt String Yes The system prompt string for the agent. setup AgentSetup Yes The setup/configuration for the agent (model, mapper, retry, etc). extensions List&lt;AgentExtension&lt;R, T, A&gt;&gt; No List of extensions to add custom logic, facts, or output schemas. knownTools Map&lt;String, ExecutableTool&gt; No Map of tool id to tool implementation for registering custom tools. toolRunApprovalSeeker ToolRunApprovalSeeker&lt;R, T, A&gt; No (Advanced) Custom approval logic for tool runs. outputValidator OutputValidator&lt;R, T&gt; No (Advanced) Custom output validation logic. errorHandler ErrorResponseHandler&lt;R&gt; No (Advanced) Custom error handling logic. <p>For most use cases, you can use the simpler constructor with just <code>outputType</code>, <code>systemPrompt</code>, <code>setup</code>, <code>extensions</code>, and <code>knownTools</code>. For advanced customization, use the full constructor and pass your own implementations for <code>toolRunApprovalSeeker</code>, <code>outputValidator</code>, or <code>errorHandler</code>.</p>"},{"location":"agents.html#example-basic-customization","title":"Example: Basic Customization","text":"<pre><code>public class BookSummarizingAgent extends Agent&lt;BookInfo, BookSummary, BookSummarizingAgent&gt; {\n    public BookSummarizingAgent(AgentSetup setup) {\n        super(BookSummary.class,\n              \"\"\"\n               You are an expert in summarizing books. You will be provided with the title and ISBN of a book.\n               You need to summarize the book and provide the topics discussed in the book.\n               \"\"\",\n              setup,\n              List.of(),\n              Map.of());\n    }\n\n    @Override\n    public String name() {\n        return \"book-summarizer\";\n    }\n}\n</code></pre>"},{"location":"agents.html#example-advanced-customization","title":"Example: Advanced Customization","text":"<pre><code>public class CustomAgent extends Agent&lt;MyRequest, MyResponse, CustomAgent&gt; {\n    public CustomAgent(AgentSetup setup,\n                       ToolRunApprovalSeeker&lt;MyRequest, MyResponse, CustomAgent&gt; approvalSeeker,\n                       OutputValidator&lt;MyRequest, MyResponse&gt; validator,\n                       ErrorResponseHandler&lt;MyRequest&gt; errorHandler) {\n        super(MyResponse.class,\n              \"Custom system prompt\",\n              setup,\n              List.of(new MyExtension()),\n              Map.of(\"myTool\", new MyTool()),\n              approvalSeeker,\n              validator,\n              errorHandler);\n    }\n    @Override\n    public String name() {\n        return \"custom-agent\";\n    }\n}\n</code></pre> <p>Use advanced options if you need to:</p> <ul> <li>approve or reject tool runs dynamically</li> <li>add custom validation logic for model outputs</li> <li>handle errors in a custom way</li> </ul>"},{"location":"agents.html#advanced-features","title":"Advanced Features","text":""},{"location":"agents.html#output-validation","title":"Output Validation","text":"<p>The <code>OutputValidator</code> interface allows you to add custom validation logic for the model's generated response. If validation fails, Sentinel AI can automatically prompt the model to fix the errors.</p> <pre><code>public class MyValidator implements OutputValidator&lt;MyRequest, MyResponse&gt; {\n    @Override\n    public OutputValidationResults validate(AgentRunContext&lt;MyRequest&gt; context, MyResponse output) {\n        if (output.getSomeField() &lt; 0) {\n            return OutputValidationResults.builder()\n                .failure(new ValidationFailure(\"someField must be non-negative\"))\n                .build();\n        }\n        return OutputValidationResults.success();\n    }\n}\n</code></pre> <p>Register it in the <code>Agent</code> constructor:</p> <pre><code>super(MyResponse.class, systemPrompt, setup, extensions, tools, approvalSeeker, new MyValidator(), errorHandler);\n</code></pre>"},{"location":"agents.html#message-pre-processors","title":"Message Pre-processors","text":"<p><code>AgentMessagesPreProcessor</code> allows you to inspect or modify the list of messages just before they are sent to the LLM. This is useful for custom compaction, PII masking, or logging.</p> <pre><code>agent.registerAgentMessagesPreProcessor((ctx, allMessages, newMessages) -&gt; {\n    // Modify messages if needed\n    return AgentMessagesPreProcessResult.builder()\n        .messages(allMessages) // Return the (modified) list\n        .build();\n});\n</code></pre>"},{"location":"agents.html#extensions","title":"Extensions","text":"<p>Extensions are a way to add additional functionality to your agent. They are exposed as modules and can be used to extend the functionality of the agent. Agents can be configured to use extensions by adding while creating the agent. The extensions are loaded in the order they are added.</p> <p>Extensions can be used to:</p> <ul> <li>Add facts to the knowledge passed to the agent in the system prompt</li> <li>Add custom tools to the agent</li> <li>Get agent to perform additional tasks</li> <li>Generate extra information from the agent</li> </ul> <p>To create an extension derive and implement the <code>AgentExtension</code> interface.</p>"},{"location":"calling-remote-services.html","title":"Calling Remote HTTP Services","text":""},{"location":"calling-remote-services.html#making-http-calls-to-remote-services","title":"Making HTTP Calls to Remote Services","text":"<p>An Agent by itself does very little. Most of the power comes from it's ability to invoke tools or a set of tools to perform a task. SentinelAI supports tool calling as a standard feature as seen in the section on Tools.</p> <p>In modern architectures, overall functionality of an organization is often split into multiple services often deployed on containerized environments. These services expose APIs that can be called by the agents to perform tasks. SentinelAI provides multiple ways of accessing functionality from remote services. The following sections describe the different ways in which an agent written using SentinelAI can access functionality provided by remote services.</p> <p>Tip</p> <p>If you have not done already, please go through the concept of ToolBoxes<code>{:target=\"_blank\"}</code> and how to register them to an agent.</p> <p>While MCP servers provide a quick way to talk to services, one of the major problems with them is that they expose a large number of tools to the agent, which can be overwhelming for the LLM and additional maintenance headache for  service providers etc. SentinelAI provides a way to call remote service APIs using HTTP calls directly from the agent using the <code>HttpToolBox</code>.</p>"},{"location":"calling-remote-services.html#nomenclature","title":"Nomenclature","text":"<p>We use the following nomenclature in rest of this section:</p> <ul> <li>Upstream - The remote service that the agent will call.</li> <li>Endpoint - The URL endpoint of the upstream service that the agent will call. This is a prefix to the api path in   the tool.</li> <li>Api - A remote HTTP API defined by <code>{Method, Path, Headers, Body}</code>.</li> <li>Template - An object that contains the type and the template for a component of the specification.   For example: { type: TEXT_SUBSTITUTION, content: \"/apis/v1/location/${user}\"}.</li> </ul>"},{"location":"calling-remote-services.html#getting-started-with-httptoolbox","title":"Getting started with <code>HttpToolBox</code>","text":"<p>HttpToolBox is implemented in a separate module called <code>sentinel-ai-toolbox-remote-http</code>. You can add it to your project using the following dependency:</p> <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n    &lt;artifactId&gt;sentinel-ai-toolbox-remote-http&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre> <p>A single HTTP toolbox represents calls to a single upstream service. This approach has several advantages:</p> <ul> <li>The calls to a particular upstream can be grouped together making it similar to using an MCP server being exposed by   the service</li> <li>Configurations such as timeouts, auth header injection, SSL certificate handling and other options to the HTTP client   can be configured based on the service being called.</li> <li>Discovery of the actual service endpoint can be different for upstream to upstream if needed, especially for   containerized/hybrid environments.</li> </ul>"},{"location":"calling-remote-services.html#http-tool-definitions","title":"HTTP Tool Definitions","text":"<p>Sentinel provides a convenient way to define remote HTTP calls as simple tools that are exposed to the LLM. The complexity of the path, body, headers are completely abstracted out. The LLM sees only simple functions and native parameters. To achieve this, Sentinel Abstracts the core <code>HttpTool</code> as <code>TemplatizedHttpTool</code>. A TemplatizedHttpTool has the following requirements:</p> <ul> <li>metadata - Consisting of name, description and parameters for the tool</li> <li>template - consisting of the HTTP method, path, headers and body templates</li> </ul>"},{"location":"calling-remote-services.html#http-tool-metadata","title":"HTTP Tool Metadata","text":"Property Type Description name <code>String</code> The name of the tool being registered. description <code>String</code> A detailed description of the tool, used by the LLM to select and use it. parameters <code>Map&lt;String, HttpToolParameterMeta&gt;</code> List of parameters that the LLM needs to pass to the tool. Map key is the parameter name. <p>HttpToolParameterMeta - Metadata for tool parameters</p> Property Type Description description <code>String</code> A description for the parameter to help the LLM send correct values. type <code>HttpToolParameterType</code> Type of the parameter. Only simple types are supported for performance and simplicity. <p>The following parameter types are supported:</p> <ul> <li><code>STRING</code></li> <li><code>BOOLEAN</code></li> <li><code>INTEGER</code></li> <li><code>LONG</code></li> <li><code>FLOAT</code></li> <li><code>DOUBLE</code></li> <li><code>BYTE</code></li> <li><code>SHORT</code></li> <li><code>CHARACTER</code></li> <li><code>STRING_ARRAY</code></li> <li><code>BOOLEAN_ARRAY</code></li> <li><code>INTEGER_ARRAY</code></li> <li><code>LONG_ARRAY</code></li> <li><code>FLOAT_ARRAY</code></li> <li><code>DOUBLE_ARRAY</code></li> <li><code>BYTE_ARRAY</code></li> <li><code>SHORT_ARRAY</code></li> <li><code>CHARACTER_ARRAY</code></li> </ul>"},{"location":"calling-remote-services.html#response-transformation","title":"Response Transformation","text":"<p>The HTTP toolbox supports transformation of the response of the API call. This is currently supported only for JSON responses. Json transformation is achieved using the powerful JOLT transformation library.</p> <p>Testing out JOLT Transformations</p> <p>You can test out JOLT transformations using the JOLT Transform Tool.</p>"},{"location":"calling-remote-services.html#http-tool-template","title":"HTTP Tool Template","text":"<p>The template for the HTTP tool is a simple object that contains the following properties:</p> Field Type Required **Description ** method <code>HttpCallSpec.HttpMethod</code> Yes The HTTP method to use for the call. path <code>Template</code> Yes The path to call, can be a template. Example: <code>/api/v1/location/${user}</code> headers <code>Map&lt;String, List&lt;Template&gt;&gt;</code> No Headers to send with the call, each value can be a template. Example: <code>{\"Authorization\": \"Bearer ${token}\"}</code> body <code>Template</code> No The body of the HTTP call, can be a template. Example: <code>{\"name\": \"${name}\"}</code>. Supported only in POST and PUT methods. contentType <code>String</code> No The content type of the body, if applicable. Example: <code>application/json</code> <p>Sample code to create a <code>TemplatizedHttpTool</code>:</p> TestTool.java<pre><code>final var tool = TemplatizedHttpTool.builder()\n        .metadata(HttpToolMetadata.builder() //Create tool metadata\n                          .name(\"getUserLocation\")\n                          .description(\"Get the location of the user\")\n                          .parameters(Map.of( //Define parameters for the tool\n                                              \"user\", HttpToolParameterMeta.builder()\n                                                      .description(\"Name of the user\")\n                                                      .type(HttpToolParameterType.STRING)\n                                                      .build()))\n                          .build())\n        .template(HttpCallTemplate.builder() // Build the HTTP call template\n                          .method(HttpCallSpec.HttpMethod.GET)\n                          .path(Template.textSubstitutor(\"/api/v1/location/${user}\"))\n                          .headers(Map.of(\n                                  \"Authorization\", List.of(Template.textSubstitutor(\"Bearer ${token}\")),\n                                  \"Client-ID\", List.of(Template.text(\"Agent-Vinod\"))))\n                          .build())\n        .responseTransformations(ResponseTransformerConfig.builder() //(Optional) Response transformation config\n                                         .type(ResponseTransformerConfig.Type.JOLT)\n                                         .config(\"\"\"\n                                                         [\n                                                           {\n                                                              \"operation\": \"shift\",\n                                                              \"spec\": {\n                                                                 \"location\": \"userLocation\"\n                                                              }\n                                                           }\n                                                         ]\n                                                         \"\"\")\n                                         .build();\n</code></pre> <p>The above code uses the <code>Template.text()</code> and <code>Template.textSubstitutor()</code> methods for simplicity.</p>"},{"location":"calling-remote-services.html#http-tool-source","title":"HTTP Tool Source","text":"<p>A <code>ToolSource</code> implementation is used to store the definition of the HttpTool instances for the upstreams. A single <code>ToolSource</code> can handle all definitions for all upstreams. SentinelAI provides a default implementation called <code>InMemoryHttpToolSource</code> that stores these definitions in Memory in a thread-safe manner. You can also implement your own on a more permanent storage if you want.</p> <p>To create an <code>InMemoryHttpToolSource</code>, you can use the following code:</p> <pre><code>final var toolSource = InMemoryHttpToolSource.builder()\n        .mapper(objectMapper) // Optional, but recommended to be sent\n        .build();\n</code></pre> <p>Parameters:</p> Parameter Type Required Description mapper ObjectMapper No Jackson ObjectMapper for JSON serialization. If null, a default mapper is created. Recommended to send expander HttpCallTemplateExpander No Expander used to convert templates to HTTP call specs. If null, a default expander is created. Recommended to not send unless a new template engine is being implemented by client."},{"location":"calling-remote-services.html#bulk-loading-predefined-tools","title":"Bulk loading predefined tools","text":"<p>SentinelAI provides a utility class called <code>HttpToolSourceReader</code> to read the tool definitions from a file and load them into a ToolSource.</p> <p>To do this, use the following code:</p> <pre><code>//To read from file\nHttpToolReaders.loadToolsFromYAML(Paths.get(\"/PATH/TO/YAML/FILE\"),toolsource);\n//To read from bytes\n        HttpToolReaders.\n\nloadToolsFromYAMLContent(Files.readAllBytes(Paths.get(\"/PATH/TO/YAML/FILE\")),toolsource);\n</code></pre>"},{"location":"calling-remote-services.html#remote-http-tool-definition-yaml-file-format","title":"Remote HTTP Tool Definition YAML file format","text":"<p>The remote HTTP tool definitions are stored in a YAML file format. The file contains a map of upstream names to a list of tools. Each tool has metadata and a definition that includes the HTTP method, path, headers, and body templates.</p> <pre><code># File is a map of upstream -&gt; tool mapping\ntest: #(1)!\n  tools: #(2)!\n    - metadata:\n        name: getName #(3)!\n        description: Get the name of the user #(4)!\n      definition:\n        method: GET\n        path:\n          type: TEXT\n          content: /api/v1/name\n    - metadata:\n        name: getLocation\n        description: Get location for specified user\n        parameters: #(5)!\n          userName: #(6)!\n            description: Name of the user #(7)!\n            type: STRING #(8)!\n      definition: #(9)!\n        method: POST #(10)!\n        path: #(11)!\n          type: TEXT #(12)!\n          content: /api/v1/location #(13)!\n        body: #(14)!\n          type: TEXT_SUBSTITUTOR\n          content: |\n            {\n              \"name\": \"${name}\"\n            }\n</code></pre> <ol> <li>Upstream name. This is used to group the tools together. The upstream name can be anything, but it is recommended    to use a meaningful name that represents the service being called.</li> <li>List of tools.</li> <li>Name of the tool.</li> <li>Description of the tool. This is used by the LLM to understand the purpose of the tool.</li> <li>Parameters for the tool. This is a map of parameter name to parameter metadata. The metadata contains the    description and type of the parameter. This is optional and only needed if some parameters need to be passed to the    tool by the LLM in the tool call.</li> <li>Name of the parameter. This is used to identify the parameter in the tool call.</li> <li>Description of the parameter. This is used by the LLM to understand the purpose of the parameter.</li> <li>Type of the parameter as defined in HttpToolParameterType.</li> <li>Tool definition.</li> <li>HTTP Method. Can be GET, POST, PUT, DELETE.</li> <li>A template for the path. The template can be a simple text or a text substitutor. The text substitutor allows     the LLM to pass parameters to the tool call.</li> <li>Type of the template. Can be TEXT or TEXT_SUBSTITUTOR. TEXT_SUBSTITUTOR allows the LLM to pass parameters to     the tool call.</li> <li>The actual path to call. Can be string if type is <code>TEXT</code> or a template pattern for <code>TEXT_SUBSTITUTOR</code>. The     template pattern can contain parameters that the LLM can fill in.</li> <li>Body template. Relevant only for POST and PUT methods. The body can be a simple text or a text substitutor.     The text substitutor allows the LLM to pass parameters to the tool call.</li> </ol> <p>Note</p> <p>The file contains HTTP call definitions for multiple upstreams. Each upstream can have multiple tools defined.</p> <p>The above file can be read and loaded into the <code>ToolSource</code> implementation you have using the <code>HttpToolSourceReader</code> utility class.</p>"},{"location":"errors.html","title":"Error Handling & Error Types","text":""},{"location":"errors.html#error-handling","title":"Error Handling","text":"<p>Sentinel AI uses a structured error handling approach. When an agent execution fails, it returns a <code>SentinelError</code> object which contains an <code>ErrorType</code> and a descriptive message.</p>"},{"location":"errors.html#the-errortype-enum","title":"The <code>ErrorType</code> Enum","text":"<p>The <code>ErrorType</code> enum defines the categories of errors that can occur during agent execution. Each error type also indicates whether it is retryable.</p> Error Type Description Retryable <code>SUCCESS</code> Operation completed successfully. No <code>NO_RESPONSE</code> No response was received from the model. Yes <code>REFUSED</code> The model refused to generate a response (e.g., safety filters). No <code>FILTERED</code> The generated content was filtered by the provider. No <code>LENGTH_EXCEEDED</code> The generated content exceeded the maximum allowed length/tokens. No <code>TOOL_CALL_PERMANENT_FAILURE</code> A tool call failed with a non-recoverable error. No <code>TOOL_CALL_TEMPORARY_FAILURE</code> A tool call failed with a transient error. Yes <code>TOOL_CALL_TIMEOUT</code> A tool call exceeded its configured timeout. Yes <code>JSON_ERROR</code> Error parsing JSON response from the model. Yes <code>SERIALIZATION_ERROR</code> Error serializing request or tool arguments to JSON. Yes <code>DESERIALIZATION_ERROR</code> Error deserializing model response or tool results. Yes <code>UNKNOWN_FINISH_REASON</code> The model stopped for an unrecognized reason. Yes <code>GENERIC_MODEL_CALL_FAILURE</code> An unspecified error occurred during the model call. Yes <code>DATA_VALIDATION_FAILURE</code> The generated output failed validation against the output schema. Yes <code>FORCED_RETRY</code> A retry was explicitly triggered (e.g., by an output validator). Yes <code>MODEL_CALL_COMMUNICATION_ERROR</code> Network or communication error with the model provider. Yes <code>MODEL_CALL_RATE_LIMIT_EXCEEDED</code> The model provider's rate limit was exceeded. Yes <code>MODEL_CALL_HTTP_FAILURE</code> The HTTP call to the model provider failed with a non-2xx status code. Yes <code>PREPROCESSOR_RUN_FAILURE</code> An error occurred while running a message pre-processor. Yes <code>PREPROCESSOR_MESSAGES_OUTPUT_INVALID</code> A pre-processor returned invalid or null messages. No <code>MODEL_RUN_TERMINATED</code> The model run was terminated by an early termination strategy. No <code>UNKNOWN</code> An unexpected error occurred. Yes"},{"location":"errors.html#handling-errors-in-code","title":"Handling Errors in Code","text":"<p>When you execute an agent, you should check the <code>isSuccessful()</code> method of the <code>AgentOutput</code>.</p> <pre><code>final var response = agent.execute(input);\n\nif (response.isSuccessful()) {\n    System.out.println(\"Result: \" + response.getData());\n} else {\n    SentinelError error = response.getError();\n    System.err.println(\"Error Type: \" + error.getErrorType());\n    System.err.println(\"Message: \" + error.getMessage());\n\n    if (error.getErrorType().isRetryable()) {\n        // Optionally implement custom retry logic if not using RetrySetup\n    }\n}\n</code></pre>"},{"location":"errors.html#retry-configuration","title":"Retry Configuration","text":"<p>As discussed in the Tool Retries &amp; Timeouts section, you can configure automatic retries for specific error types using <code>RetrySetup</code>.</p> <pre><code>final var retrySetup = RetrySetup.builder()\n        .totalAttempts(3)\n        .retriableErrorTypes(Set.of(ErrorType.MODEL_CALL_COMMUNICATION_ERROR, ErrorType.MODEL_CALL_RATE_LIMIT_EXCEEDED))\n        .build();\n</code></pre>"},{"location":"messages-session.html","title":"Chat Messages and Session Management","text":""},{"location":"messages-session.html#chat-messages-and-session-management","title":"Chat Messages and Session Management","text":"<p>The <code>AgentSessionExtension</code> provides automated conversation history management and session summarization for Sentinel AI agents. It ensures that agents maintain context across multiple turns by persisting messages and injecting relevant history and summaries into subsequent interactions.</p>"},{"location":"messages-session.html#features","title":"Features","text":"<ul> <li>Automated Message Persistence: Saves all user and agent messages to a configured storage backend.</li> <li>Conversation Summarization: Automatically generates and updates session summaries based on token usage thresholds.</li> <li>Context Injection: Injects the latest session summary as a fact in the system prompt.</li> <li>History Retrieval: Automatically retrieves and injects previous messages from the session history into the model context.</li> <li>Pre-filtering: Supports filtering messages before persistence (e.g., removing system prompts or failed tool calls).</li> <li>Message Selection: Supports selecting specific messages for context (e.g., removing unpaired tool calls).</li> </ul>"},{"location":"messages-session.html#tools","title":"Tools","text":"<p>Unlike the Memory or Registry extensions, the <code>AgentSessionExtension</code> does not expose any tools to the agent. It operates strictly through automated background processes: 1.  Fact Injection: Injects the current session summary into the system prompt. 2.  History Injection: Prepends historical messages to the message list before calling the model. 3.  Post-Processing: Captures new messages and triggers summarization after the agent execution finishes.</p>"},{"location":"messages-session.html#configuration","title":"Configuration","text":"<p>The extension is configured using the <code>AgentSessionExtensionSetup</code> class.</p> Setting Type Default Description <code>historicalMessageFetchSize</code> <code>int</code> 30 Number of historical messages to fetch in a single batch. <code>maxSummaryLength</code> <code>int</code> 1000 Maximum character length for the generated session summary. <code>autoSummarizationThresholdPercentage</code> <code>int</code> 60 Percentage of the model's context window usage that triggers automatic summarization. Set to 0 to summarize every run. <code>compactionPrompts</code> <code>CompactionPrompts</code> DEFAULT Custom prompts used for the summarization process."},{"location":"messages-session.html#usage","title":"Usage","text":"<p>To use the session extension, add it to your agent's extension list during initialization.</p> <pre><code>final var sessionExtension = AgentSessionExtension.&lt;MyRequest, MyResponse, MyAgent&gt;builder()\n        .sessionStore(sessionStore) // Implementation of SessionStore\n        .mapper(objectMapper)\n        .setup(AgentSessionExtensionSetup.builder()\n                .autoSummarizationThresholdPercentage(70)\n                .build())\n        .build();\n\nfinal var agent = new MyAgent(setup, List.of(sessionExtension), Map.of());\n</code></pre> <p>Session ID Requirement</p> <p>The session extension relies on a <code>sessionId</code> being present in the <code>AgentRequestMetadata</code>. If no <code>sessionId</code> is provided during execution, the extension will skip history persistence and retrieval.</p> <pre><code>final var response = agent.execute(AgentInput.&lt;MyRequest&gt;builder()\n        .request(new MyRequest(...))\n        .requestMetadata(AgentRequestMetadata.builder()\n                .sessionId(\"session-123\")\n                .userId(\"user-456\")\n                .build())\n        .build());\n</code></pre>"},{"location":"messages-session.html#session-storage-implementations","title":"Session Storage Implementations","text":"<p>Sentinel AI provides multiple implementations for the <code>SessionStore</code> interface.</p>"},{"location":"messages-session.html#filesystem-storage","title":"Filesystem Storage","text":"<p>The <code>FileSystemSessionStore</code> stores session data and messages as JSON files on the local disk. This is suitable for development or single-node deployments.</p> <p>Dependency: </p><pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n    &lt;artifactId&gt;sentinel-ai-filesystem&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><p></p> <p>Implementation: </p><pre><code>final var sessionStore = new FileSystemSessionStore(\"/path/to/storage\", objectMapper);\n</code></pre><p></p>"},{"location":"messages-session.html#elasticsearch-storage","title":"Elasticsearch Storage","text":"<p>The <code>ESSessionStore</code> provides a scalable implementation using Elasticsearch. It supports efficient searching and pagination of sessions and messages.</p> <p>Dependency: </p><pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n    &lt;artifactId&gt;sentinel-ai-storage-es&lt;/artifactId&gt;\n&lt;/dependency&gt;\n</code></pre><p></p> <p>Implementation: </p><pre><code>final var esClient = ESClient.builder()\n        .serverUrl(\"http://localhost:9200\")\n        .apiKey(\"optional-api-key\")\n        .build();\n\nfinal var sessionStore = ESSessionStore.builder()\n        .client(esClient)\n        .mapper(objectMapper)\n        .indexPrefix(\"my-application\") // Optional prefix for indices\n        .build();\n</code></pre><p></p>"},{"location":"messages-session.html#automatic-summarization-compaction","title":"Automatic Summarization (Compaction)","text":"<p>One of the most powerful features of the session extension is its ability to automatically \"compact\" conversation history when it grows too large.</p>"},{"location":"messages-session.html#how-it-works","title":"How it Works","text":"<ol> <li>Token Estimation: After each agent run, the extension estimates the number of tokens in the current session history using the model's <code>estimateTokenCount</code> method.</li> <li>Threshold Evaluation: It compares the estimated token count against the model's <code>contextWindowSize</code> (configured in <code>ModelSettings</code>).</li> <li>Trigger: If <code>(estimatedTokens / contextWindowSize) * 100 &gt; autoSummarizationThresholdPercentage</code>, the extension triggers a summarization task.</li> <li>Processing: The summarization task runs asynchronously using the <code>MessageCompactor</code>.</li> </ol>"},{"location":"messages-session.html#model-attributes-configuration","title":"Model Attributes Configuration","text":"<p>To ensure accurate threshold evaluation, you should configure the <code>ModelAttributes</code> within your <code>ModelSettings</code>. This tells Sentinel AI about the specific limits and encoding of the model you are using.</p> <pre><code>final var modelSettings = ModelSettings.builder()\n        .modelAttributes(ModelAttributes.builder()\n                .contextWindowSize(128_000) // (1)!\n                .encodingType(EncodingType.CL100K_BASE) // (2)!\n                .build())\n        .temperature(0.7f)\n        .build();\n</code></pre> <ol> <li>Context Window Size: The total number of tokens the model can handle (e.g., 128k for GPT-4o).</li> <li>Encoding Type: The tokenizer used for counting (e.g., <code>CL100K_BASE</code> for OpenAI models, <code>O200K_BASE</code> for GPT-4o).</li> </ol>"},{"location":"messages-session.html#compaction-prompts-customization","title":"Compaction Prompts Customization","text":"<p>You can customize how the summarization is performed by providing a <code>CompactionPrompts</code> object in the setup.</p> <pre><code>final var customPrompts = CompactionPrompts.builder()\n        .summarizationSystemPrompt(\"You are a expert at distilling chat history...\")\n        .summarizationUserPrompt(\"Please summarize these messages: ${sessionMessages}\")\n        .promptSchema(myJsonSchema) // (1)!\n        .build();\n</code></pre> <ol> <li>You can provide a custom JSON schema to change the structure of the generated summary.</li> </ol>"},{"location":"messages-session.html#default-summary-schema","title":"Default Summary Schema","text":"<p>By default, the compactor generates a structured output based on the following JSON schema:</p> <pre><code>{\n  \"type\": \"object\",\n  \"properties\": {\n    \"title\": { \"type\": \"string\" }, // (1)!\n    \"keywords\": { // (2)!\n      \"type\": \"array\",\n      \"items\": { \"type\": \"string\" }\n    },\n    \"summary\": { \"type\": \"string\" }, // (3)!\n    \"key_points\": { // (4)!\n      \"type\": \"array\",\n      \"items\": { \"type\": \"string\" }\n    },\n    \"key_facts\": { // (5)!\n      \"type\": \"array\",\n      \"items\": { \"type\": \"string\" }\n    },\n    \"sentiment\": { // (6)!\n      \"type\": \"string\",\n      \"enum\": [\"positive\", \"neutral\", \"negative\"]\n    },\n    \"confidence\": { \"type\": \"number\" } // (7)!\n  },\n  \"required\": [\"title\", \"keywords\", \"summary\", \"key_points\", \"key_facts\", \"sentiment\", \"confidence\"]\n}\n</code></pre> <ol> <li>Title: A human-readable heading capturing the essence of the conversation.</li> <li>Keywords: Relevant topics (1-3 tags).</li> <li>Summary: Concise narrative capturing context and outcomes.</li> <li>Key Points: Distilled takeaways ordered by importance.</li> <li>Key Facts: Objective, verifiable facts extracted from the source.</li> <li>Sentiment: Overall tone of the content.</li> <li>Confidence: Model-assessed confidence in the summary (0-10).</li> </ol>"},{"location":"messages-session.html#behaviour","title":"Behaviour","text":""},{"location":"messages-session.html#conversation-history","title":"Conversation History","text":"<p>When an agent execution starts, the extension fetches historical messages from the <code>SessionStore</code>. It uses <code>MessageSelector</code> implementations (like <code>UnpairedToolCallsRemover</code>) to ensure the retrieved history is clean and coherent for the LLM.</p>"},{"location":"messages-session.html#facts-injection","title":"Facts Injection","text":"<p>The latest summary is injected into the system prompt as a fact: </p><pre><code>&lt;knowledge&gt;\n    &lt;facts&gt;\n        &lt;description&gt;Information about session session-123&lt;/description&gt;\n        &lt;fact&gt;\n            &lt;name&gt;A summary of the conversation in this session&lt;/name&gt;\n            &lt;content&gt;The user asked about book summaries and the agent provided details for War and Peace.&lt;/content&gt;\n        &lt;/fact&gt;\n    &lt;/facts&gt;\n&lt;/knowledge&gt;\n</code></pre><p></p>"},{"location":"messages-session.html#notes","title":"Notes","text":"<ul> <li>Summarization happens asynchronously after the main agent execution is completed to avoid increasing latency for the user.</li> <li>The extension automatically handles \"compaction\" when the model returns a <code>LENGTH_EXCEEDED</code> error, ensuring the next run has a summarized context.</li> </ul>"},{"location":"messages-session.html#warnings","title":"Warnings","text":"<ul> <li>Concurrent Access: While storage implementations like <code>ESSessionStore</code> are thread-safe, concurrent updates to the same session summary might lead to race conditions where one summary overwrites another.</li> <li>Storage Growth: Without a cleanup policy, session and message indices can grow significantly. Ensure you have a data retention strategy in place.</li> </ul>"},{"location":"messages-session.html#caution-footguns","title":"Caution: Footguns","text":"<p>Manual Message Management</p> <p>Avoid passing <code>oldMessages</code> in <code>AgentInput</code> while using the <code>AgentSessionExtension</code>. The extension automatically retrieves history from the store. Providing <code>oldMessages</code> manually can result in duplicate messages or incorrect message ordering in the model prompt, as <code>oldMessages</code> are injected before the system prompt and extension-managed history.</p> <p>Changing Model Context Windows</p> <p>If you change the model used by an agent to one with a significantly smaller context window, existing sessions might fail with <code>LENGTH_EXCEEDED</code> before the automatic summarization can catch up. Monitor your token usage closely when switching models.</p>"},{"location":"observability.html","title":"Observability & Events","text":""},{"location":"observability.html#observability","title":"Observability","text":"<p>Sentinel AI is designed with observability in mind. It provides a consolidated event bus that broadcasts key lifecycle events of an agentic run, allowing you to monitor performance, debug tool calls, and track token usage in real-time.</p>"},{"location":"observability.html#event-bus","title":"Event Bus","text":"<p>Each <code>Agent</code> instance has an <code>EventBus</code> that broadcasts events. You can subscribe to this bus to log activities, push metrics to external systems (like Prometheus or Datadog), or trigger custom side-effects.</p>"},{"location":"observability.html#subscribing-to-events","title":"Subscribing to Events","text":"<p>You can access the event bus via the <code>Agent</code> or <code>AgentSetup</code>:</p> <pre><code>agent.getEventBus().connect(event -&gt; {\n    System.out.println(\"Received event: \" + event.getType());\n\n    // Use the AgentEventVisitor for type-safe handling\n    event.accept(new AgentEventVisitor&lt;Void&gt;() {\n        @Override\n        public Void visit(InputReceivedAgentEvent event) {\n            System.out.println(\"User input: \" + event.getContent());\n            return null;\n        }\n\n        @Override\n        public Void visit(ToolCalledAgentEvent event) {\n            System.out.println(\"Calling tool: \" + event.getToolCallName());\n            return null;\n        }\n\n        @Override\n        public Void visit(OutputGeneratedAgentEvent event) {\n            System.out.println(\"Model usage: \" + event.getUsage());\n            return null;\n        }\n\n        // ... handle other events\n    });\n});\n</code></pre>"},{"location":"observability.html#core-event-types","title":"Core Event Types","text":"<p>Sentinel AI broadcasts the following events during an agent's execution:</p> Event Type Description <code>INPUT_RECEIVED</code> Broadcasted when a new request is received by the agent. <code>MESSAGE_RECEIVED</code> Broadcasted when a response is received from the model. <code>TOOL_CALLED</code> Broadcasted before a tool is executed. Contains tool name and arguments. <code>TOOL_CALL_COMPLETED</code> Broadcasted after a tool execution finishes. Contains the result or error. <code>TOOL_CALL_APPROVAL_DENIED</code> Broadcasted if a tool execution was rejected by a <code>ToolRunApprovalSeeker</code>. <code>OUTPUT_GENERATED</code> Broadcasted when the final response is generated. Contains token usage and the response object. <code>OUTPUT_ERROR</code> Broadcasted if an error occurs during processing. <code>MESSAGE_SENT</code> Broadcasted when a message is sent to the model."},{"location":"observability.html#model-usage-stats","title":"Model Usage Stats","text":"<p>For every run, Sentinel AI tracks detailed token usage statistics in the <code>ModelUsageStats</code> object. This is available in the <code>AgentOutput</code> and also broadcasted in the <code>OutputGeneratedAgentEvent</code>.</p>"},{"location":"observability.html#token-details","title":"Token Details","text":"<p>The usage stats include breakdowns for: * Request Tokens: Tokens used in the input (system prompt, tools, history, facts). * Response Tokens: Tokens generated by the model. * Cached Tokens: Tokens retrieved from the model's cache (if supported by the provider). * Reasoning Tokens: Tokens used by reasoning models (like OpenAI's o1 series) for internal thought.</p> <p>Example of accessing usage stats from an event:</p> <pre><code>@Override\npublic Void visit(OutputGeneratedAgentEvent event) {\n    ModelUsageStats stats = event.getUsage();\n    log.info(\"Request Tokens: {}, Response Tokens: {}, Reasoning: {}\", \n        stats.getRequestTokens(), \n        stats.getResponseTokens(),\n        stats.getResponseTokenDetails().getReasoningTokens());\n    return null;\n}\n</code></pre>"},{"location":"observability.html#logging","title":"Logging","text":"<p>By default, Sentinel AI uses SLF4J for logging. You can enable debug logging for <code>com.phonepe.sentinelai</code> to see detailed information about prompt generation, tool discovery, and internal processing.</p> <pre><code># Example logback or log4j config\nlogging.level.com.phonepe.sentinelai=DEBUG\n</code></pre>"},{"location":"tools.html","title":"Using Tools in Agents","text":""},{"location":"tools.html#tool-call-support","title":"Tool Call Support","text":"<p>Major power of an AI agent comes from it's ability to invoke a tool or a set of tools to perform a task. Sentinel AI supports tool calling as a standard feature.</p> <ul> <li>Tools can be defined as part of the agent class itself and are auto-discovered during instantiation</li> <li>Tool methods can have complex object types as input and output. they can also optionally have an instance of   <code>AgentRunContext</code> as the first parameter.</li> <li>Tool methods need to be described using the <code>@Tool</code> annotation</li> <li>Tool methods from other c lasses can be registered at runtime or during agent creation.</li> <li>SentinelAI provides an abstraction called <code>ToolBox</code> to allow developers to build libraries of tools that do related   work. ToolBoxes can be registered with the agent dynamically.</li> </ul>"},{"location":"tools.html#the-agentruncontext-class","title":"The <code>AgentRunContext</code> class","text":"<p>The <code>AgentRunContext</code> class is used to pass information between the agent and the tool. It can be passed as the first parameter to the tool method. Along with other stuff, the context can be used to access the current user request being processed, the request metadata and so on.</p> Member Type Description <code>runId</code> <code>String</code> An ID for this particular run, used to track the run in logs and events. <code>request</code> <code>R</code> The user request being processed. <code>requestMetadata</code> <code>AgentRequestMetadata</code> Metadata for the request, such as session and user information. <code>agentSetup</code> <code>AgentSetup</code> Required setup for the agent, including model and tool configurations. <code>oldMessages</code> <code>List&lt;AgentMessage&gt;</code> List of old messages exchanged during the agent's interaction. <code>modelUsageStats</code> <code>ModelUsageStats</code> Tracks usage statistics for the model during this run."},{"location":"tools.html#tools-as-part-of-the-agent-class","title":"Tools as part of the agent class","text":"<p>SentinelAI will auto register all methods defined as part of the agent class. The methods need to be annotated with <code>@Tool</code> for this functionality to work.</p> TestAgent.java<pre><code>class TestAgent extends Agent&lt;String, String, TestAgent&gt; {\n\n    @JsonClassDescription(\"Information about the user\")\n    private record UserInfo(//(1)!\n            @JsonProperty(required = true)\n            @JsonPropertyDescription(\"Name of the user\")\n            String name) {\n    }\n\n    public TestAgent(@NonNull AgentSetup setup) {\n        super(String.class,\n              \"Greet the user\",\n              setup,\n              List.of(),\n              Map.of());\n    }\n\n    @Tool(\"Call this tool to get appropriate greeting for the user\")//(2)!\n    public String greet(final UserInfo userInfo) {\n        return \"Hello \" + userInfo.name();\n    }\n\n    @Override\n    public String name() {\n        return \"test-agent\";\n    }\n}\n</code></pre> <ol> <li>Complex object type for the input parameter. Document everything properly using appropriate annotations.</li> <li>Tool Description. Make it verbose and clear. This will be used to generate the tool description for the LLM.</li> </ol> <p>Tip</p> <p>The <code>@JsonProperty</code> and <code>JsonPropertyDescription</code> annotations are used to mark the parameter as required and to provide a description for the parameter. It is highly recommended to provide documentation for the tool itself and it's parameters to help the LLM understand the usage for the tools better.</p>"},{"location":"tools.html#externally-defined-tools","title":"Externally defined tools","text":"<p>External tools can be defined and registered with the agent at runtime or at startup. This is useful when you want to create a library of tools that can be used by multiple agents. The tools can be defined as part of a <code>ToolBox</code> or registered individually.</p>"},{"location":"tools.html#registering-methods-from-other-classes-as-tools","title":"Registering methods from other classes as tools","text":"<p>You can register methods from other classes as tools when instantiating the agent. SentinelAI provides the <code>ToolUtils</code>  utility class to easily read and register methods from other classes. The methods need to be annotated with <code>@Tool</code> for this functionality to work.</p> <p>Let's say the tool is defined in an external class called <code>ExternalClass</code>:</p> ExternalClass.java<pre><code>public class ExternalClass {\n    @Tool(\"Get appropriate greeting for the user\")\n    public String greet(@JsonProperty(required = true)\n                        @JsonPropertyDescription(\"Name of the user\")\n                        String name) {\n        return \"Hello \" + name;\n    }\n}\n</code></pre> <p>These tools can be used when creating the agent like so: </p>TestAgent.java<pre><code>public class TestAgent extends Agent&lt;String, String, TestAgent&gt; {\n\n    public TestAgent(@NonNull AgentSetup setup) {\n        super(String.class,\n              \"Greet the user\",\n              setup,\n              List.of(),\n              ToolUtils.fromObject(new ExternalClass()));//(1)!\n    }\n\n    @Override\n    public String name() {\n        return \"test-agent\";\n    }\n}\n</code></pre><p></p> <ol> <li>The <code>ToolUtils.fromObject</code> (or <code>ToolUtils.readTools</code>) method will read all the methods annotated with <code>@Tool</code> and      register them with the agent. The methods can have complex object types as input and output. They can also      optionally have an instance of <code>AgentRunContext</code> as the first parameter.</li> </ol> <p>As seen in the example, tools can be read and registered directly during agent creation, or by calling the <code>registerTools</code> method.</p>"},{"location":"tools.html#tool-retries-timeouts","title":"Tool Retries &amp; Timeouts","text":"<p>SentinelAI supports configuring retries and timeouts at both the model level and the individual tool level.</p>"},{"location":"tools.html#model-call-retries-timeouts","title":"Model Call Retries &amp; Timeouts","text":"<p>The <code>ModelSettings</code> object allows you to configure a global timeout for LLM calls using <code>java.time.Duration</code>. Additionally, you can provide a <code>RetrySetup</code> in <code>AgentSetup</code> to handle transient failures.</p> <pre><code>final var agentSetup = AgentSetup.builder()\n        .model(model)\n        .modelSettings(ModelSettings.builder()\n                .timeout(Duration.ofSeconds(30)) //(1)!\n                .build())\n        .retrySetup(RetrySetup.builder()\n                .totalAttempts(3) //(2)!\n                .delayAfterFailedAttempt(Duration.ofSeconds(1))\n                .retriableErrorTypes(Set.of(ErrorType.JSON_ERROR, ErrorType.MODEL_CALL_COMMUNICATION_ERROR)) //(3)!\n                .build())\n        .build();\n</code></pre> <ol> <li>Global timeout for the model call.</li> <li>Number of retry attempts.</li> <li>Specific error types that should trigger a retry.</li> </ol>"},{"location":"tools.html#individual-tool-timeouts","title":"Individual Tool Timeouts","text":"<p>You can also specify timeouts for individual tools using the <code>@Tool</code> annotation. This is useful for tools that might perform long-running operations.</p> <pre><code>@Tool(value = \"Long running operation\", timeoutSeconds = 60)\npublic String longRunningTool() {\n    // implementation\n}\n</code></pre>"},{"location":"tools.html#using-toolbox","title":"Using ToolBox","text":"<p><code>ToolBox</code> is a very simple interface to define a set of tools that are related to each other. The tools can be registered with the agent all together by registering the toolbox using the <code>registerToolbox</code> methods.</p> TestToolBox.java<pre><code>public class TestToolBox implements ToolBox {\n    @Override\n    public String name() {\n        return \"test-toolbox\";\n    }\n\n    @Tool(\"Get appropriate greeting for the user\")\n    public String greet(@JsonProperty(required = true)\n                        @JsonPropertyDescription(\"Name of the user\")\n                        String name) {\n        return \"Hello \" + name;\n    }\n}\n</code></pre> <p>Create the agent as before:</p> TestAgent.java<pre><code>public class TestAgent extends Agent&lt;String, String, TestAgent&gt; {\n\n    public TestAgent(@NonNull AgentSetup setup) {\n        super(String.class,\n              \"Greet the user\",\n              setup,\n              List.of(),\n              Map.of());\n    }\n\n    @Override\n    public String name() {\n        return \"test-agent\";\n    }\n}\n</code></pre> <p>Register the toolbox(es) at runtime:</p> <pre><code>final var agent = new TestAgent(agentSetup)\n                        .registerToolbox(new TestToolBox());\n//Use agent\n</code></pre> <p>Tip</p> <p>We recommend combining related functionality into toolboxes and making libraries out of them to be used across agent.</p>"},{"location":"using-mcp-servers.html","title":"Using MCP Servers","text":""},{"location":"using-mcp-servers.html#using-mcp-servers","title":"Using MCP Servers","text":"<p>An Agent by itself does very little. Most of the power comes from it's ability to invoke tools or a set of tools to perform a task. SentinelAI supports tool calling as a standard feature as seen in the section on Tools.</p> <p>MCP servers are servers that implement the Model Context Protocol (MCP) and expose tools that can be used by agents. These servers can be run locally or remotely and can be used to register tools with the agent.</p> <p>SentinelAI supports using MCP servers to register tools. This is useful when you want to create a library of tools and host them centrally to be used by multiple agents without needing to write them. There are many other open-source and useful MCP servers available on the internet.</p> <p>Support for MCP functionality</p> <p>Currently Sentinel AI supports making tool calls (with dynamic tool list changes tracking) and sampling. Other MCP features like prompt templates, resources and elicitation etc. are not supported. </p> <p>MCP Transport</p> <p>SentinelAI supports two types of MCP transports: <code>stdio</code> and <code>sse</code>. The <code>stdio</code> transport is used for local servers that can be run using a command line interface, while the <code>sse</code> transport is used for remote servers (or servers hosted locally using containers) that support Server-Sent Events (SSE).</p> <p>MCP Server security</p> <p>Please ensure MCP servers you decide to use off the internet are secure and come from trusted sources. Also scope exposure of tools provided by MCP servers to the minimum required for your agent to function. Please go through the following sections to understand how this can be achieved in SentinelAI.</p> <p>The toolbox can be added to your project using the following dependency:</p> <p></p><pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;com.phonepe.sentinel-ai&lt;/groupId&gt;\n    &lt;artifactId&gt;sentinel-ai-toolbox-mcp&lt;/artifactId&gt;\n    &lt;version&gt;${sentinel.version}&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre> This provides the <code>MCPToolBox</code> and <code>ComposingToolBox</code> classes t oconnect to and use tools from MCP servers.<p></p>"},{"location":"using-mcp-servers.html#using-mcptoolbox","title":"Using MCPToolBox","text":"<p>Then create the MCP client:</p> TestAgent.java<pre><code>// Build the client as prescribed in https://modelcontextprotocol.io/sdk/java/mcp-client\nfinal var params = ServerParameters.builder(\"npx\")\n                .args(\"-y\", \"@modelcontextprotocol/server-everything@2025.12.18\")\n                .build();\nfinal var transport = new StdioClientTransport(params);\n\nfinal var mcpClient = McpClient.sync(transport)\n        .build();\nmcpClient.initialize();\n</code></pre> <p>Create the <code>MCPToolBox</code> and register the toolbox to the agent:</p> TestAgent.java<pre><code>//Create and register a toolbox to the agent\nfinal var mcpToolBox = new MCPToolBox(\"test\", mcpClient, objectMapper, Set.of());\nagent.registerToolbox(mcpToolBox);\n</code></pre> <p>This will register all the tools from the mcp server with the agent.</p> <p>Toolbox Name</p> <p>All ToolBoxes should be given a meaningful name. This is used to generate unique ids for all the tools exposed by the MCPServer</p>"},{"location":"using-mcp-servers.html#filtering-tools-from-mcp-server","title":"Filtering tools from MCP server","text":"<p>One of the major problems with using multiple or large MCP servers is that it will make available a lot of tools that might be irrelevant to the context of the agent, but will still end up taking space in the context and tend to confuse the LLM. To mitigate this, SentinelAI provides a way to filter the tools being exposed to the agent.</p> <p>The <code>MCPToolBox</code> constructor accepts a set of tool names which are the identifiers for the tools.</p> <pre><code>//This will expose only the \"echo\" and \"sum\" tools to the LLM\nfinal var mcpToolBox = new MCPToolBox(\"test\", mcpClient, objectMapper, Set.of(\"echo\", \"sum\"));\n</code></pre> <p>This can be done programatically later as well using the <code>exposeTools</code> method as follows:</p> TestAgent.java<pre><code>mcpToolBox.exposeTools(\"echo\", \"sum\");\n</code></pre> <p>You can call this method repeatedly to add more tools to the set of exposed tools. If you want to expose all tools you can use the folliwing method:</p> <p></p>TestAgent.java<pre><code>mcpToolBox.exposeAllTools();\n</code></pre> This will reset the set of exposed tools to all the tools available in the MCP server.<p></p>"},{"location":"using-mcp-servers.html#connecting-to-multiple-mcp-servers","title":"Connecting to multiple MCP servers","text":"<p>For more complex use, cases, you might want to connect to multiple MCP servers. However, the authors of most servers would expose many tools for each server that may not be relevant to your user case. To solve this problem, SentinelAI supports connecting to multiple MCP servers using the <code>ComposingToolBox</code>.</p> <p>This toolbox allows you to:</p> <ul> <li>use <code>mcp.json</code> file to define multiple MCP servers to connect to</li> <li>Create a <code>ComposingToolBox</code> and register multiple MCP clients with ability to expose selected tools in each of them</li> </ul>"},{"location":"using-mcp-servers.html#using-mcpjson-to-build","title":"Using <code>mcp.json</code> to build","text":"<p>Over time, a standard way oif configuring MCP servers has emerged. The <code>mcp.json</code> file is a JSON file that contains a map of MCP servers with relevant coordinates and parameters.</p> <p>Format: </p><pre><code>{\n  \"mcpServers\": { //(1)!\n    \"everythingServer\": { //(2)!\n      \"type\": \"stdio\", //(3)!\n      \"command\": \"npx\", //(4)!\n      \"args\": [ //(5)!\n        \"-y\",\n        \"@modelcontextprotocol/server-everything@2025.12.18\"\n      ],\n      \"env\" : { //(6)!\n        \"VAR1\": \"value1\",\n        \"Var2\": \"value2\"\n      },\n      \"exposedTools\": [\"sum\", \"echo\"] //(7)!\n    },\n    \"someOtherServer\": {\n      \"type\": \"sse\", //(8)!\n      \"url\": \"http://localhost:3001\", //(9)!\n      \"timeout\": 5000, //(10)!\n      \"knownTools\": [\"getUserLocation\", \"getUserName\"]\n    }\n  }\n}\n</code></pre><p></p> <ol> <li>The <code>mcpServers</code> key contains a map of MCP server names to their configurations.</li> <li>A unique name for the MCP server. This is used to identify the server in the code.</li> <li>The <code>type</code> of the MCP server. Currently, only <code>stdio</code> and <code>sse</code> are supported. For locally running servers this    should be set to <code>stdio</code>.</li> <li>Mandatory for <code>stdio</code> type servers, this is the command to run the MCP server. The <code>args</code> field contains the    arguments to pass to the command.</li> <li>The <code>args</code> field contains the arguments to pass to the command. This is an array of strings. This is optional.</li> <li>The <code>env</code> field is optional and contains environment variables to set when starting the MCP server. This is optional.</li> <li>The <code>exposedTools</code> field is a list of tool names that should be exposed to the agent. This is optional and    sentinel defaults to exposing all tools exposed by the MCP server to the LLM. This is useful to filter out tools    that are not relevant to the agent. This is not a standard field and is specific to SentinelAI.</li> <li>For remote servers with Server-Sent Events (SSE) support, the <code>type</code> is <code>sse</code>.</li> <li>The <code>url</code> field is the URL of the remote MCP server. This is mandatory for <code>sse</code> type servers.</li> <li>Timeout in milliseconds for the connection to the remote MCP server. This is optional and defaults to 5000ms.</li> </ol> <p>Ensuring efficiency</p> <p>When using multiple MCP servers, it is recommended to expose only the tools that are relevant to the agent's functionality. Please refer to documentation of the relevant MCP servers to set proper parameters and expose only relevant tools.</p> <p>To create and use <code>ComposingToolBox</code>, you can use the following code:</p> TestAgent.java<pre><code>// Create a ComposingToolBox using the mcp.json file\nfinal var composingMCPToolBox = ComposingMCPToolBox.buildFromFile()\n                .name(\"MCP Servers for Test Agent\")\n                .objectMapper(objectMapper)\n                .mcpJsonPath(\"/path/to/mcp.json\")\n                .build();\nagent.registerToolbox(mcpToolBox);\n</code></pre> <p>It is possible to load multiple mcp json files into a pre-built <code>ComposingToolBox</code>:</p> TestAgent.java<pre><code>MCPJsonReader.loadFile(\"/path/to/mcp.json\", //Path to the mcp.json file\n                       mcpToolBox, //Pre built ComposingMCPToolBox. does not matter how it was created\n                       objectMapper); //For serialization and deserialization of tools, arguments etc\n</code></pre>"},{"location":"using-mcp-servers.html#adding-mcp-servers-programmatically","title":"Adding MCP servers programmatically","text":"<p>Clients to MCP servers can be added to <code>ComposingToolBox</code> programmatically as well.</p> <p>To build a <code>ComposingToolBox</code> programmatically, you can use the following code:</p> TestAgent.java<pre><code>// Build the client as prescribed in https://modelcontextprotocol.io/sdk/java/mcp-client\nfinal var params = ServerParameters.builder(\"npx\")\n                .args(\"-y\", \"@modelcontextprotocol/server-everything@2025.12.18\")\n                .build();\nfinal var transport = new StdioClientTransport(params);\n\nfinal var mcpClient = McpClient.sync(transport)\n        .build();\nmcpClient.initialize();\n\n// Build toolbox\nfinal val toolBox = ComposingMCPToolBox.buildEmpty()\n        .objectMapper(objectMapper)\n        .build();\n\ntoolBox.registerExistingMCP(\"everythingServer\", mcpClient, \"add\");\ntoolBox.registerExistingMCP(\"someOtherServer\", otherServerMcpClient, Set.of(\"getUserLocation\", \"getUserName\"));\n</code></pre> <p>To override the exposed tools from a server, use the <code>exposeTools</code> method as follows: </p> TestAgent.java<pre><code>toolBox.exposeTools(\"everythingServer\", \"echo\", \"sum\");\ntoolBox.exposeTools(\"otherServer\", Set.of(\"echo\", \"sum\"));\n</code></pre> <p>To expose all tools from a server, use the <code>exposeAllTools</code> method as follows:</p> TestAgent.java<pre><code>toolBox.exposeAllTools(\"everythingServer\");\n</code></pre> <p>Warning</p> <p>Please note the following nuances about the above methods:</p> <ul> <li>Both the <code>exposeTools</code> and <code>exposeAllTools</code> methods can be used only after the MCP server has been registered.</li> <li>The <code>exposeTools</code> operations are additive. The elements/set passed to <code>exposeTools</code> method will be added to the      tools configure to be exposed from the server. If you want to remove some exposed tools use the <code>exposeAllTools</code>      method to reset the list and then rebuild it.</li> <li>Always rethink and ensure you are not exposing too many tools to the agent. This can lead to confusion and      inefficiency in the LLM's responses.</li> </ul>"}]}