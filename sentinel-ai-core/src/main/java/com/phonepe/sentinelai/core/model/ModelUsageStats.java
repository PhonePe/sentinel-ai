package com.phonepe.sentinelai.core.model;

import lombok.*;

import java.util.HashMap;
import java.util.Map;
import java.util.concurrent.atomic.AtomicReference;
import java.util.function.UnaryOperator;

/**
 * Model usage object.
 * Usage Notes:
 *  - The *Unsafe methods are not thread safe. they need to be wrapped in the {@link ModelUsageStats#safeUpdate(UnaryOperator)} when calling
 */
@Getter
@NoArgsConstructor
@ToString
@EqualsAndHashCode
@SuppressWarnings("NonAtomicOperationOnVolatileField")
public class ModelUsageStats {

    @NoArgsConstructor(access = AccessLevel.PRIVATE)
    @Getter
    @ToString
    @EqualsAndHashCode
    public static class PromptTokenDetails {
        /**
         * Cached tokens present in the prompt.
         */
        private volatile int cachedTokens = 0;
        /**
         * Audio input tokens present in the prompt.
         */
        private volatile int audioTokens = 0;

    }

    @NoArgsConstructor(access = AccessLevel.PRIVATE)
    @Getter
    @ToString
    @EqualsAndHashCode
    public static class ResponseTokenDetails {
        /**
         * Tokens generated by the model for reasoning.
         */
        private volatile int reasoningTokens = 0;
        /**
         * When using Predicted Outputs, the number of tokens in the prediction that appeared in the completion.
         */
        private volatile int acceptedPredictionTokens = 0;
        /**
         * When using Predicted Outputs, the number of tokens in the prediction that did not appear in the completion
         * . However, like reasoning tokens, these tokens are still counted in the total completion tokens for
         * purposes of billing, output, and context window limits.
         */
        private volatile int rejectedPredictionTokens = 0;
        /**
         * Audio input tokens generated by the model.
         */
        private volatile int audioTokens = 0;
    }

    /**
     * Number of request made for this run
     */
    private volatile int requestsForRun = 0;

    /**
     * Tool calls made for this run
     */
    private volatile int toolCallsForRun = 0;

    /**
     * Number of request/prompt tokens used in this run. Eqv to "prompt_tokens" param in open-ai usage object.
     */
    private volatile int requestTokens = 0;

    /**
     * Number of completion/response tokens used in this run. Eqv to "completion_tokens" param in open-ai usage object.
     */
    private volatile int responseTokens = 0;

    /**
     * Total tokens used in the whole run. Eqv to "total_tokens" param in open-ai usage object.
     */
    private volatile int totalTokens = 0;

    /**
     * Token usage for prompts
     */
    private final PromptTokenDetails requestTokenDetails = new PromptTokenDetails();

    /**
     * Token usage for responses
     */
    private final ResponseTokenDetails responseTokenDetails = new ResponseTokenDetails();

    private final AtomicReference<Map<String, Integer>> details = new AtomicReference<>(new HashMap<>());
    // Any extra details returned by the model.

    public ModelUsageStats incrementRequestsForRunUnsafe() {
        return incrementRequestsForRunUnsafe(1);
    }

    public ModelUsageStats incrementRequestsForRunUnsafe(int value) {
        this.requestsForRun += value;
        return this;
    }

    public ModelUsageStats incrementToolCallsForRunUnsafe() {
        return incrementToolCallsForRunUnsafe(1);
    }

    public ModelUsageStats incrementToolCallsForRunUnsafe(int value) {
        this.toolCallsForRun += value;
        return this;
    }

    public ModelUsageStats incrementRequestTokensUnsafe(int value) {
        this.requestTokens += value;
        return this;
    }

    public ModelUsageStats incrementResponseTokensUnsafe(int value) {
        this.responseTokens += value;
        return this;
    }

    public ModelUsageStats incrementTotalTokensUnsafe(int value) {
        this.totalTokens += value;
        return this;
    }

    public ModelUsageStats incrementRequestCachedTokensUnsafe(int value) {
        this.requestTokenDetails.cachedTokens += value;
        return this;
    }

    public ModelUsageStats incrementRequestAudioTokensUnsafe(int value) {
        this.requestTokenDetails.audioTokens += value;
        return this;
    }

    public ModelUsageStats incrementResponseReasoningTokensUnsafe(int value) {
        this.responseTokenDetails.reasoningTokens += value;
        return this;
    }

    public ModelUsageStats incrementResponseAcceptedPredictionTokensUnsafe(int value) {
        this.responseTokenDetails.acceptedPredictionTokens += value;
        return this;
    }

    public ModelUsageStats incrementResponseRejectedPredictionTokensUnsafe(int value) {
        this.responseTokenDetails.rejectedPredictionTokens += value;
        return this;
    }

    public ModelUsageStats incrementResponseAudioTokensUnsafe(int value) {
        this.responseTokenDetails.audioTokens += value;
        return this;
    }

    public ModelUsageStats addDetailsUnsafe(final Map<String, Integer> otherDetails) {
        if (null != otherDetails) {
            details.get().putAll(otherDetails);
        }
        return this;
    }

    public Map<String, Integer> getDetails() {
        return Map.copyOf(details.get());
    }

    public synchronized ModelUsageStats safeUpdate(UnaryOperator<ModelUsageStats> updater) {
        return updater.apply(this);
    }

    //Merge details from another usage object
    public ModelUsageStats merge(final ModelUsageStats other) {
        if (null == other) {
            return this;
        }
        safeUpdate(obj -> obj.incrementRequestsForRunUnsafe(other.requestsForRun)
                .incrementToolCallsForRunUnsafe(other.toolCallsForRun)
                .incrementRequestTokensUnsafe(other.requestTokens)
                .incrementResponseTokensUnsafe(other.responseTokens)
                .incrementTotalTokensUnsafe(other.totalTokens)
                .addDetailsUnsafe(other.details.get())
                //Request params
                .incrementRequestCachedTokensUnsafe(other.requestTokenDetails.cachedTokens)
                .incrementRequestAudioTokensUnsafe(other.requestTokenDetails.audioTokens)
                //Response params
                .incrementResponseReasoningTokensUnsafe(other.responseTokenDetails.reasoningTokens)
                .incrementResponseAcceptedPredictionTokensUnsafe(other.responseTokenDetails.acceptedPredictionTokens)
                .incrementResponseRejectedPredictionTokensUnsafe(other.responseTokenDetails.rejectedPredictionTokens)
                .incrementResponseAudioTokensUnsafe(other.responseTokenDetails.audioTokens))
        ;
        return this;
    }
}
